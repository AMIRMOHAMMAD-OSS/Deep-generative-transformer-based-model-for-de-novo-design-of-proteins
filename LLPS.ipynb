{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AMIRMOHAMMAD-OSS/Deep-generative-transformer-based-model-for-de-novo-design-of-proteins/blob/main/LLPS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Liquid-Liquid Phase Separation (LLPS) Protein Scorer!\n",
        "\n",
        "This tool allows you to analyze protein sequences for their propensity to undergo phase separation:\n",
        "\n",
        "Input Options:\n",
        "Upload a single protein sequence directly into the designated box.\n",
        "Alternatively, load a FASTA or TXT file containing multiple protein sequences.\n",
        "\n",
        "To maintain efficiency, we advise against loading more than 100 sequences at once\n",
        "\n",
        "Specify the sequence ID or directory for your analysis.\n",
        "\n",
        "By setting the 'End_Sequence'  parameter,you can focus the scoring on sequences up to the specified endpoint.\n",
        "\n",
        "         \n",
        "\n",
        "\n",
        "\n",
        "#BLAST+ tool\n",
        "You can utilize the BLAST+ tool to run ncbi BLAST searches on either your protein sequence or your FASTA file against your dataset. This powerful tool allows you to compare sequences and identify homologous regions, aiding in various biological analyses.\n"
      ],
      "metadata": {
        "id": "XJ8r7M6CJzke"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "hyzTHwf8dRBy"
      },
      "outputs": [],
      "source": [
        "#@title Importing libraries\n",
        "!git clone https://github.com/AMIRMOHAMMAD-OSS/classi\n",
        "!pip install biopython\n",
        "!apt-get update\n",
        "!apt-get install -y ncbi-blast+\n",
        "!pip install command_runner\n",
        "from command_runner import command_runner\n",
        "!pip install plotly\n",
        "!pip install --upgrade \"kaleido==0.1.*\"\n",
        "import kaleido\n",
        "\n",
        "from Bio import SeqIO\n",
        "from Bio.Seq import Seq\n",
        "from Bio import pairwise2\n",
        "from google.colab import files\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "import zipfile\n",
        "import shutil\n",
        "from transformers import AutoTokenizer\n",
        "from tqdm import tqdm\n",
        "!pip install slack-sdk\n",
        "from tqdm.contrib.slack import tqdm, trange\n",
        "import math\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "import numpy as np\n",
        "import time\n",
        "from collections import defaultdict\n",
        "import torch\n",
        "from torch.utils.data.dataloader import DataLoader\n",
        "import time\n",
        "import os\n",
        "import sys\n",
        "import json\n",
        "import random\n",
        "from ast import literal_eval\n",
        "import numpy as np\n",
        "import torch\n",
        "from transformers import AutoTokenizer\n",
        "from transformers import AutoTokenizer\n",
        "from tokenizers import Tokenizer, decoders, models, normalizers, pre_tokenizers, trainers\n",
        "from transformers import CanineTokenizer, CanineModel\n",
        "tokenizer = Tokenizer.from_file(\"classi/Trained_BPE2.json\")\n",
        "tokenizer.model_max_length = 256\n",
        "tokenizer\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler as Sc\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.model_selection import train_test_split as TTS\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "\n",
        "from sklearn.model_selection import train_test_split as TTS\n",
        "\n",
        "\n",
        "def edit(x):\n",
        "    for i in x:\n",
        "      if i in \"BJOUX\\Z_n\\n\":\n",
        "        x = x.replace(i,\"\")\n",
        "      else:\n",
        "        pass\n",
        "    return x\n",
        "\n",
        "def encode(x):\n",
        "  l = []\n",
        "  chars = tokenizer.get_vocab()\n",
        "  for i in x:\n",
        "    l.append(chars[i])\n",
        "  return l\n",
        "\n",
        "with open(\"classi/training.txt\",\"r\",encoding=\"utf-8\") as f:\n",
        "  text = f.read()\n",
        "  k = \"#\".join([i for i in edit(text).split(\"<|edoftext|>\")])\n",
        "chars = tokenizer.get_vocab()\n",
        "vocab_size = len(tokenizer.get_vocab())\n",
        "\n",
        "with open(\"classi/validation.txt\",\"r\",encoding=\"utf-8\") as f:\n",
        "  text = f.read()\n",
        "  l = \"#\".join([i for i in edit(text).split(\"<|edoftext|>\")])\n",
        "\n",
        "def Padding(x,PAD = 0,max_len = 512):\n",
        "  l = []\n",
        "  max_len = max(512,len(max(x,key = lambda x: len(x))))\n",
        "  for i in x:\n",
        "    a = i\n",
        "    if len(a) < max_len:\n",
        "      a = a + [PAD for i in range(max_len-len(a))]\n",
        "    l.append(a)\n",
        "  return np.array(l).reshape(len(x),max_len)\n",
        "with open(\"classi/negative_dataset.txt\") as x:\n",
        "  c = x.read()\n",
        "Filtered_train  = [i for i in k.split(\"#\") if len(i)<= 512][1:]\n",
        "Filtered_val = [i for i in l.split(\"#\") if len(i)<= 512][1:]\n",
        "Filtered_neg = [i for i in c.split(\"\\n\") if len(i)<= 512]\n",
        "pos = Filtered_train + Filtered_val\n",
        "pos2 = [i for i in k.split(\"#\")][1:] +  [i for i in l.split(\"#\")][1:]\n",
        "with open(\"DrLLPS.fasta\",\"w\") as w:\n",
        "  for i in range(len(pos2)):\n",
        "    w.write(\">seq{i}\\n\".format(i=i))\n",
        "    w.write(pos2[i]+\"\\n\")\n",
        "  w.close()\n",
        "\n",
        "files.download(\"DrLLPS.fasta\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "cellView": "form",
        "id": "Yc9VXFLYN-x6"
      },
      "outputs": [],
      "source": [
        "#@title Loading models and requierments\n",
        "\n",
        "def set_seed(seed):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "def setup_logging(config):\n",
        "    work_dir = config.system.work_dir\n",
        "    os.makedirs(work_dir, exist_ok=True)\n",
        "    with open(os.path.join(work_dir, 'args.txt'), 'w') as f:\n",
        "        f.write(' '.join(sys.argv))\n",
        "    with open(os.path.join(work_dir, 'config.json'), 'w') as f:\n",
        "        f.write(json.dumps(config.to_dict(), indent=4))\n",
        "\n",
        "class CfgNode:\n",
        "    def __init__(self, **kwargs):\n",
        "        self.__dict__.update(kwargs)\n",
        "\n",
        "    def __str__(self):\n",
        "        return self._str_helper(0)\n",
        "\n",
        "    def _str_helper(self, indent):\n",
        "        parts = []\n",
        "        for k, v in self.__dict__.items():\n",
        "            if isinstance(v, CfgNode):\n",
        "                parts.append(\"%s:\\n\" % k)\n",
        "                parts.append(v._str_helper(indent + 1))\n",
        "            else:\n",
        "                parts.append(\"%s: %s\\n\" % (k, v))\n",
        "        parts = [' ' * (indent * 4) + p for p in parts]\n",
        "        return \"\".join(parts)\n",
        "\n",
        "    def to_dict(self):\n",
        "        return { k: v.to_dict() if isinstance(v, CfgNode) else v for k, v in self.__dict__.items() }\n",
        "\n",
        "    def merge_from_dict(self, d):\n",
        "        self.__dict__.update(d)\n",
        "\n",
        "    def merge_from_args(self, args):\n",
        "\n",
        "        for arg in args:\n",
        "            keyval = arg.split('=')\n",
        "            assert len(keyval) == 2, \"expecting each override arg to be of form --arg=value, got %s\" % arg\n",
        "            key, val = keyval\n",
        "            try:\n",
        "                val = literal_eval(val)\n",
        "            except ValueError:\n",
        "                pass\n",
        "\n",
        "            assert key[:2] == '--'\n",
        "            key = key[2:]\n",
        "            keys = key.split('.')\n",
        "            obj = self\n",
        "            for k in keys[:-1]:\n",
        "                obj = getattr(obj, k)\n",
        "            leaf_key = keys[-1]\n",
        "            assert hasattr(obj, leaf_key), f\"{key} is not an attribute that exists in the config\"\n",
        "            print(\"command line overwriting config attribute %s with %s\" % (key, val))\n",
        "            setattr(obj, leaf_key, val)\n",
        "\n",
        "import math\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "\n",
        "class SiLU(nn.Module):\n",
        "   def forward(self, x):\n",
        "        return x*F.sigmoid(x)\n",
        "\n",
        "class NY(nn.Module):\n",
        "  def forward(self,x):\n",
        "    return 3*torch.tanh(0.3*x)\n",
        "\n",
        "class NewGELU(nn.Module):\n",
        "    def forward(self, x):\n",
        "        return 0.5 * x * (1.0 + torch.tanh(math.sqrt(2.0 / math.pi) * (x + 0.044715 * torch.pow(x, 3.0))))\n",
        "\n",
        "class SelfAttention(nn.Module):\n",
        "\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        assert config.n_embd % config.n_head == 0\n",
        "        self.c_attn = nn.Linear(config.n_embd, 3 * config.n_embd)\n",
        "        self.c_proj = nn.Linear(config.n_embd, config.n_embd)\n",
        "        self.attn_dropout = nn.Dropout(config.attn_pdrop)\n",
        "        self.resid_dropout = nn.Dropout(config.resid_pdrop)\n",
        "        self.register_buffer(\"bias\", torch.tril(torch.ones(config.block_size, config.block_size))\n",
        "                                     .view(1, 1, config.block_size, config.block_size))\n",
        "        self.n_head = config.n_head\n",
        "        self.n_embd = config.n_embd\n",
        "\n",
        "    def forward(self, x):\n",
        "        B, T, C = x.size()\n",
        "        q, k ,v  = self.c_attn(x).split(self.n_embd, dim=2)\n",
        "        k = k.view(B, T, self.n_head, C // self.n_head).transpose(1, 2)\n",
        "        q = q.view(B, T, self.n_head, C // self.n_head).transpose(1, 2)\n",
        "        v = v.view(B, T, self.n_head, C // self.n_head).transpose(1, 2)\n",
        "        att = (q @ k.transpose(-2, -1)) * (1.0 / math.sqrt(k.size(-1)))\n",
        "        att = att.masked_fill(self.bias[:,:,:T,:T] == 0, float('-inf'))\n",
        "        att = F.softmax(att, dim=-1)\n",
        "        att = self.attn_dropout(att)\n",
        "        y = att @ v\n",
        "        y = y.transpose(1, 2).contiguous().view(B, T, C)\n",
        "        y = self.resid_dropout(self.c_proj(y))\n",
        "        return y\n",
        "\n",
        "class Block(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.ln_1 = nn.LayerNorm(config.n_embd)\n",
        "        self.attn = SelfAttention(config)\n",
        "        self.ln_2 = nn.LayerNorm(config.n_embd)\n",
        "        self.mlp = nn.ModuleDict(dict(\n",
        "            c_fc    = nn.Linear(config.n_embd, 4 * config.n_embd),\n",
        "            c_proj  = nn.Linear(4 * config.n_embd, config.n_embd),\n",
        "            act     = NewGELU(),\n",
        "            dropout = nn.Dropout(config.resid_pdrop),\n",
        "        ))\n",
        "        m = self.mlp\n",
        "        self.mlpf = lambda x: m.dropout(m.c_proj(m.act(m.c_fc(x))))\n",
        "    def forward(self, x):\n",
        "        x = x + self.attn(self.ln_1(x))\n",
        "        x = x + self.mlpf(self.ln_2(x))\n",
        "        return x\n",
        "\n",
        "class ClassifierII(nn.Module):\n",
        "    @staticmethod\n",
        "    def get_default_config():\n",
        "        C = CfgNode()\n",
        "        C.model_type = 'gpt'\n",
        "        C.n_layer = None\n",
        "        C.n_head = None\n",
        "        C.n_embd =  None\n",
        "        C.vocab_size = len(chars)\n",
        "        C.max_length = 512\n",
        "        C.embd_pdrop = 0.1\n",
        "        C.resid_pdrop = 0.1\n",
        "        C.attn_pdrop = 0.1\n",
        "        return C\n",
        "\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.max_length = config.block_size\n",
        "        self.soft = nn.Softmax(1)\n",
        "        self.config = self.get_default_config()\n",
        "        self.device = \"cuda\"\n",
        "        self.model_states = {'h':{'n_layer': 48, 'n_head': 25, 'n_embd': 1600},\n",
        "                                    'g':{'n_layer': 12, '': 12, 'n_embd': 768},\n",
        "                'f':   {'n_layer': 24, 'n_head': 16, 'n_embd': 1024},\n",
        "                'e':   {'n_layer': 36, 'n_head': 20, 'n_embd': 1280},\n",
        "                'd':{'n_layer': 8, 'n_head': 16, 'n_embd': 512},\n",
        "                'c':{'n_layer': 6, 'n_head': 6, 'n_embd': 192},\n",
        "                'b':{'n_layer': 4, 'n_head': 4, 'n_embd': 128},\n",
        "                'a':{'n_layer': 3, 'n_head': 3, 'n_embd': 48}}\n",
        "\n",
        "        type_ = config.model_type is not None\n",
        "        #assert type_ in \"abcdefgh\"\n",
        "        p = all([config.n_layer is not None, config.n_head is not None, config.n_embd is not None])\n",
        "        #assert type_ == True and p == True\n",
        "        if type_:\n",
        "            config.merge_from_dict(self.model_states[config.model_type])\n",
        "        self.closs = nn.BCELoss()\n",
        "        self.ny = NY()\n",
        "        self.l = nn.Linear(512,1,64)\n",
        "        self.transformer = nn.ModuleDict(dict(\n",
        "            wte = nn.Embedding(config.vocab_size, config.n_embd),\n",
        "            wpe = nn.Embedding(config.max_length, config.n_embd),\n",
        "            drop = nn.Dropout(config.embd_pdrop),\n",
        "            h = nn.ModuleList([Block(config) for _ in range(config.n_layer)]),\n",
        "            ln_f = nn.LayerNorm(config.n_embd),))\n",
        "        self.classifier_head = nn.Sequential(#nn.Tanh(),\n",
        "                                             nn.Linear(config.n_embd, 2)\n",
        "                                             )\n",
        "        self.apply(self._init_weights)\n",
        "        for pn, p in self.named_parameters():\n",
        "            if pn.endswith('c_proj.weight'):\n",
        "                torch.nn.init.normal_(p, mean=0.0, std=0.02/math.sqrt(2 * config.n_layer))\n",
        "\n",
        "        n_params = sum(p.numel() for p in self.transformer.parameters())\n",
        "        print(\"[ Number of trainable parameters: %.2fM ]\" % (n_params/1e6,))\n",
        "\n",
        "    def _init_weights(self, module):\n",
        "        if isinstance(module, nn.Linear):\n",
        "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
        "            if module.bias is not None:\n",
        "                torch.nn.init.zeros_(module.bias)\n",
        "        elif isinstance(module, nn.Embedding):\n",
        "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
        "        elif isinstance(module, nn.LayerNorm):\n",
        "            torch.nn.init.zeros_(module.bias)\n",
        "            torch.nn.init.ones_(module.weight)\n",
        "\n",
        "    @classmethod\n",
        "    def from_pretrained(cls, model_type):\n",
        "        from transformers import GPT2LMHeadModel\n",
        "        config = cls.get_default_config()\n",
        "        config.model_type = model_type\n",
        "        config.vocab_size = 25\n",
        "        config.max_length = 512\n",
        "        model = ClassifierII(config)\n",
        "        sd = model.state_dict()\n",
        "        model_hf = GPT2LMHeadModel.from_pretrained(model_type)\n",
        "        sd_hf = model_hf.state_dict()\n",
        "        keys = [k for k in sd_hf if not k.endswith('attn.masked_bias')]\n",
        "        transposed = ['attn.c_attn.weight', 'attn.c_proj.weight', 'mlp.c_fc.weight', 'mlp.c_proj.weight']\n",
        "        assert len(keys) == len(sd)\n",
        "        for k in keys:\n",
        "            if any(k.endswith(w) for w in transposed):\n",
        "                assert sd_hf[k].shape[::-1] == sd[k].shape\n",
        "                with torch.no_grad():\n",
        "                    sd[k].copy_(sd_hf[k].t())\n",
        "            else:\n",
        "                assert sd_hf[k].shape == sd[k].shape\n",
        "                with torch.no_grad():\n",
        "                    sd[k].copy_(sd_hf[k])\n",
        "        return model\n",
        "\n",
        "    def configure_optimizers(self, train_config):\n",
        "        decay = set()\n",
        "        no_decay = set()\n",
        "        whitelist_weight_modules = (torch.nn.Linear, )\n",
        "        blacklist_weight_modules = (torch.nn.LayerNorm, torch.nn.Embedding)\n",
        "        for mn, m in self.named_modules():\n",
        "            for pn, p in m.named_parameters():\n",
        "                fpn = '%s.%s' % (mn, pn) if mn else pn\n",
        "                if pn.endswith('bias'):\n",
        "                    no_decay.add(fpn)\n",
        "                elif pn.endswith('weight') and isinstance(m, whitelist_weight_modules):\n",
        "                    decay.add(fpn)\n",
        "                elif pn.endswith('weight') and isinstance(m, blacklist_weight_modules):\n",
        "                    no_decay.add(fpn)\n",
        "        param_dict = {pn: p for pn, p in self.named_parameters()}\n",
        "        inter_params = decay & no_decay\n",
        "        union_params = decay | no_decay\n",
        "        assert len(inter_params) == 0, \"parameters %s made it into both decay/no_decay sets!\" % (str(inter_params), )\n",
        "        assert len(param_dict.keys() - union_params) == 0, \"parameters %s were not separated into either decay/no_decay set!\" \\\n",
        "                                                    % (str(param_dict.keys() - union_params), )\n",
        "        optim_groups = [\n",
        "            {\"params\": [param_dict[pn] for pn in sorted(list(decay))], \"weight_decay\": train_config.weight_decay},\n",
        "            {\"params\": [param_dict[pn] for pn in sorted(list(no_decay))], \"weight_decay\": 0.0},]\n",
        "        optimizer = torch.optim.AdamW(optim_groups, lr=train_config.learning_rate, betas=train_config.betas)\n",
        "        return optimizer\n",
        "\n",
        "    @torch.no_grad\n",
        "    def predict_proba(self,idx,j =\"None\"):\n",
        "      sigmoid = nn.Sigmoid()\n",
        "      soft = nn.Softmax(dim=1)\n",
        "      ny = NY()\n",
        "      si = SiLU()\n",
        "      self.eval()\n",
        "      x,_ = self.forward(idx)\n",
        "      if j == \"None\":\n",
        "        return x[:,0:1]\n",
        "      elif j == \"soft\":\n",
        "        return self.soft(x)[:,0:1]\n",
        "      else:\n",
        "        return sigmoid(x)[:,0:1]\n",
        "\n",
        "    @torch.no_grad\n",
        "    def predict(self,idx):\n",
        "      g = torch.zeros((idx.shape[0],1))\n",
        "      e = -1\n",
        "      for i in self.predict_proba(idx):\n",
        "        e+=1\n",
        "        if i[0].item()>=0.5:\n",
        "          g[e] = 1\n",
        "      return g\n",
        "\n",
        "    def forward(self, idx, targets=None):\n",
        "        device = idx.device\n",
        "        b, t = idx.size()\n",
        "        pos = torch.arange(0, t, dtype=torch.long, device=device).unsqueeze(0)\n",
        "        tok_emb = self.transformer.wte(idx)\n",
        "        pos_emb = self.transformer.wpe(pos)\n",
        "        x = self.transformer.drop(tok_emb + pos_emb)\n",
        "        for block in self.transformer.h:\n",
        "            x = block(x)\n",
        "        x = self.transformer.ln_f(x)\n",
        "        logits = self.classifier_head(x).view(b,2,t).to(device)\n",
        "        logits = self.l(logits)\n",
        "        logits = F.sigmoid(self.ny(logits).view(b,2).mean(1).view(b,1))\n",
        "        loss = None\n",
        "        if targets is not None:\n",
        "            loss = F.binary_cross_entropy(logits,targets)\n",
        "        return logits, loss\n",
        "\n",
        "\n",
        "class Trainer:\n",
        "    @staticmethod\n",
        "    def get_default_config():\n",
        "        C = CfgNode()\n",
        "        C.device = 'cuda'\n",
        "        C.num_workers = 4\n",
        "        C.max_iters = None\n",
        "        C.batch_size = 128\n",
        "        C.max_length = 512\n",
        "        C.learning_rate = 8e-4\n",
        "        C.betas = (0.9, 0.95)\n",
        "        C.weight_decay = 0.1\n",
        "        C.grad_norm_clip = 1.0\n",
        "        return C\n",
        "\n",
        "    def __init__(self, config, model, train_dataset,val_dataset):\n",
        "        self.config = config\n",
        "        self.model = model\n",
        "        self.optimizer = None\n",
        "        self.train_dataset = train_dataset\n",
        "        self.val_dataset = val_dataset\n",
        "        self.callbacks = defaultdict(list)\n",
        "        self.device ='cuda'\n",
        "        self.model = self.model.to(self.device)\n",
        "        self.iter_num = 0\n",
        "        self.iter_time = 0.0\n",
        "        self.iter_dt = 0.0\n",
        "\n",
        "    def add_callback(self, onevent: str, callback):\n",
        "        self.callbacks[onevent].append(callback)\n",
        "\n",
        "    def set_callback(self, onevent: str, callback):\n",
        "        self.callbacks[onevent] = [callback]\n",
        "\n",
        "    def trigger_callbacks(self, onevent: str):\n",
        "        for callback in self.callbacks.get(onevent, []):\n",
        "            callback(self)\n",
        "\n",
        "    def run(self):\n",
        "        model, config = self.model, self.config\n",
        "        self.optimizer = model.configure_optimizers(config)\n",
        "        batch_size = self.config.batch_size\n",
        "        def get_batch(mode):\n",
        "            batch_size = 64\n",
        "            if mode == \"train\":\n",
        "              data = train_dataset\n",
        "              pos_train = torch.tensor(np.array([data[i:i+1,:] for i in range(data.shape[0]) if data[i,-1].item() == 1]).reshape(len([data[i:i+1,:] for i in range(data.shape[0]) if data[i,-1].item() == 1]),513))\n",
        "              neg_train = torch.tensor(np.array([data[i:i+1,:] for i in range(data.shape[0]) if data[i,-1].item() == 0]).reshape(len([data[i:i+1,:] for i in range(data.shape[0]) if data[i,-1].item() == 0]),513))\n",
        "              N = np.random.randint(batch_size)\n",
        "              ix_pos = np.random.randint(pos_train.shape[0]-N)\n",
        "              ix_neg = np.random.randint(neg_train.shape[0]-batch_size-N)\n",
        "              pos_data = pos_train[ix_pos:ix_pos+N,:]\n",
        "              neg_data = neg_train[ix_neg:ix_neg+batch_size-N,:]\n",
        "              data = torch.concat((pos_data,neg_data))\n",
        "              seq = data[:,:-1]\n",
        "              targets = torch.zeros((batch_size,1), device=\"cuda\")\n",
        "              o = -1\n",
        "              for i in data:\n",
        "                o+=1\n",
        "                if i[-1].item() == 1:\n",
        "                  targets[o] = 1\n",
        "                #else:\n",
        "                  #targets[o][1] = 1\n",
        "            else:\n",
        "              data = val_dataset\n",
        "              ix = np.random.randint(data.shape[0]-batch_size)\n",
        "              data = data[ix:ix+batch_size,:]\n",
        "              seq = data[:,:-1]\n",
        "              targets = torch.zeros((batch_size,1), device=\"cuda\")\n",
        "              o = -1\n",
        "              for i in data:\n",
        "                o+=1\n",
        "                if i[-1].item() == 1:\n",
        "                  targets[o] = 1\n",
        "                #else:\n",
        "                 # targets[o][1] = 1\n",
        "            targets = targets.view(batch_size,1).to(\"cuda\")\n",
        "            seq = seq.view(batch_size,512).to(\"cuda\")\n",
        "            return seq, targets\n",
        "\n",
        "        @torch.no_grad\n",
        "        def cross_val():\n",
        "          model.eval()\n",
        "          out = []\n",
        "          for i in [\"train\",\"val\"]:\n",
        "            losses = torch.zeros(200+1)\n",
        "            for k in range(200):\n",
        "              X,Y = get_batch(i)\n",
        "              logits,loss = model(X,Y)\n",
        "              losses[k]=loss.item()\n",
        "              out1 = losses.mean()\n",
        "            out.append(out1)\n",
        "          model.train()\n",
        "          return out\n",
        "        losses = cross_val()\n",
        "        LOSS = [losses]\n",
        "        print(\"\\n[train loss = {k}, val loss =  {j}]\\n\".format(k = losses[0],j = losses[1]))\n",
        "        model.train()\n",
        "        for epoch in range(20):\n",
        "          print(\"[epoch {o}] \\n\".format(o = epoch))\n",
        "          iters = 200\n",
        "          for i in range(iters):\n",
        "            if i == 0:\n",
        "              Y = \"| =\"\n",
        "            elif i == iters -1 :\n",
        "              Y = \"=> 100% |\"\n",
        "            else:\n",
        "              if i%(int(iters/50)) == 0 :\n",
        "                Y = \"=\"\n",
        "              else:\n",
        "                Y = \"\"\n",
        "            print(\"{y}\".format(y = Y),end=\"\")\n",
        "            x, y = get_batch(\"train\")\n",
        "            logits, self.loss = model(x, y)\n",
        "            model.zero_grad(set_to_none=True)\n",
        "            self.loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), config.grad_norm_clip)\n",
        "            self.optimizer.step()\n",
        "          losses = cross_val()\n",
        "          LOSS.append(losses)\n",
        "          print(LOSS)\n",
        "          print(\"\\n[train loss = {k}, val loss =  {j}]\\n\".format(k = losses[0],j = losses[1]))\n",
        "        PATH = \"model {h}\".format(h = model_config.model_type)\n",
        "        torch.save(model.state_dict(), PATH)\n",
        "\n",
        "def set_seed(seed):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "def setup_logging(config):\n",
        "    work_dir = config.system.work_dir\n",
        "    os.makedirs(work_dir, exist_ok=True)\n",
        "    with open(os.path.join(work_dir, 'args.txt'), 'w') as f:\n",
        "        f.write(' '.join(sys.argv))\n",
        "    with open(os.path.join(work_dir, 'config.json'), 'w') as f:\n",
        "        f.write(json.dumps(config.to_dict(), indent=4))\n",
        "\n",
        "class CfgNode:\n",
        "    def __init__(self, **kwargs):\n",
        "        self.__dict__.update(kwargs)\n",
        "\n",
        "    def __str__(self):\n",
        "        return self._str_helper(0)\n",
        "\n",
        "    def _str_helper(self, indent):\n",
        "        parts = []\n",
        "        for k, v in self.__dict__.items():\n",
        "            if isinstance(v, CfgNode):\n",
        "                parts.append(\"%s:\\n\" % k)\n",
        "                parts.append(v._str_helper(indent + 1))\n",
        "            else:\n",
        "                parts.append(\"%s: %s\\n\" % (k, v))\n",
        "        parts = [' ' * (indent * 4) + p for p in parts]\n",
        "        return \"\".join(parts)\n",
        "\n",
        "    def to_dict(self):\n",
        "        return { k: v.to_dict() if isinstance(v, CfgNode) else v for k, v in self.__dict__.items() }\n",
        "\n",
        "    def merge_from_dict(self, d):\n",
        "        self.__dict__.update(d)\n",
        "\n",
        "    def merge_from_args(self, args):\n",
        "\n",
        "        for arg in args:\n",
        "            keyval = arg.split('=')\n",
        "            assert len(keyval) == 2, \"expecting each override arg to be of form --arg=value, got %s\" % arg\n",
        "            key, val = keyval\n",
        "            try:\n",
        "                val = literal_eval(val)\n",
        "            except ValueError:\n",
        "                pass\n",
        "\n",
        "            assert key[:2] == '--'\n",
        "            key = key[2:]\n",
        "            keys = key.split('.')\n",
        "            obj = self\n",
        "            for k in keys[:-1]:\n",
        "                obj = getattr(obj, k)\n",
        "            leaf_key = keys[-1]\n",
        "            assert hasattr(obj, leaf_key), f\"{key} is not an attribute that exists in the config\"\n",
        "            print(\"command line overwriting config attribute %s with %s\" % (key, val))\n",
        "            setattr(obj, leaf_key, val)\n",
        "\n",
        "import math\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "\n",
        "class SiLU(nn.Module):\n",
        "   def forward(self, x):\n",
        "        return x*F.sigmoid(x)\n",
        "\n",
        "class NY(nn.Module):\n",
        "  def forward(self,x):\n",
        "    return 3*torch.tanh(0.3*x)\n",
        "\n",
        "class NewGELU(nn.Module):\n",
        "    def forward(self, x):\n",
        "        return 0.5 * x * (1.0 + torch.tanh(math.sqrt(2.0 / math.pi) * (x + 0.044715 * torch.pow(x, 3.0))))\n",
        "\n",
        "class SelfAttention(nn.Module):\n",
        "\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        assert config.n_embd % config.n_head == 0\n",
        "        self.c_attn = nn.Linear(config.n_embd, 3 * config.n_embd)\n",
        "        self.c_proj = nn.Linear(config.n_embd, config.n_embd)\n",
        "        self.attn_dropout = nn.Dropout(config.attn_pdrop)\n",
        "        self.resid_dropout = nn.Dropout(config.resid_pdrop)\n",
        "        self.register_buffer(\"bias\", torch.tril(torch.ones(config.block_size, config.block_size))\n",
        "                                     .view(1, 1, config.block_size, config.block_size))\n",
        "        self.n_head = config.n_head\n",
        "        self.n_embd = config.n_embd\n",
        "\n",
        "    def forward(self, x):\n",
        "        B, T, C = x.size()\n",
        "        q, k ,v  = self.c_attn(x).split(self.n_embd, dim=2)\n",
        "        k = k.view(B, T, self.n_head, C // self.n_head).transpose(1, 2)\n",
        "        q = q.view(B, T, self.n_head, C // self.n_head).transpose(1, 2)\n",
        "        v = v.view(B, T, self.n_head, C // self.n_head).transpose(1, 2)\n",
        "        att = (q @ k.transpose(-2, -1)) * (1.0 / math.sqrt(k.size(-1)))\n",
        "        att = att.masked_fill(self.bias[:,:,:T,:T] == 0, float('-inf'))\n",
        "        att = F.softmax(att, dim=-1)\n",
        "        att = self.attn_dropout(att)\n",
        "        y = att @ v\n",
        "        y = y.transpose(1, 2).contiguous().view(B, T, C)\n",
        "        y = self.resid_dropout(self.c_proj(y))\n",
        "        return y\n",
        "\n",
        "class Block(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.ln_1 = nn.LayerNorm(config.n_embd)\n",
        "        self.attn = SelfAttention(config)\n",
        "        self.ln_2 = nn.LayerNorm(config.n_embd)\n",
        "        self.mlp = nn.ModuleDict(dict(\n",
        "            c_fc    = nn.Linear(config.n_embd, 4 * config.n_embd),\n",
        "            c_proj  = nn.Linear(4 * config.n_embd, config.n_embd),\n",
        "            act     = NewGELU(),\n",
        "            dropout = nn.Dropout(config.resid_pdrop),\n",
        "        ))\n",
        "        m = self.mlp\n",
        "        self.mlpf = lambda x: m.dropout(m.c_proj(m.act(m.c_fc(x))))\n",
        "    def forward(self, x):\n",
        "        x = x + self.attn(self.ln_1(x))\n",
        "        x = x + self.mlpf(self.ln_2(x))\n",
        "        return x\n",
        "\n",
        "class ClassifierI(nn.Module):\n",
        "    @staticmethod\n",
        "    def get_default_config():\n",
        "        C = CfgNode()\n",
        "        C.model_type = 'gpt'\n",
        "        C.n_layer = None\n",
        "        C.n_head = None\n",
        "        C.n_embd =  None\n",
        "        C.vocab_size = len(chars)\n",
        "        C.max_length = 512\n",
        "        C.embd_pdrop = 0.1\n",
        "        C.resid_pdrop = 0.1\n",
        "        C.attn_pdrop = 0.1\n",
        "        return C\n",
        "\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.max_length = config.block_size\n",
        "        self.soft = nn.Softmax(1)\n",
        "        self.config = self.get_default_config()\n",
        "        self.device = \"cpu\"\n",
        "        self.model_states = {'h':{'n_layer': 48, 'n_head': 25, 'n_embd': 1600},\n",
        "                                    'g':{'n_layer': 12, '': 12, 'n_embd': 768},\n",
        "                'f':   {'n_layer': 24, 'n_head': 16, 'n_embd': 1024},\n",
        "                'e':   {'n_layer': 36, 'n_head': 20, 'n_embd': 1280},\n",
        "                'd':{'n_layer': 8, 'n_head': 16, 'n_embd': 512},\n",
        "                'c':{'n_layer': 6, 'n_head': 6, 'n_embd': 192},\n",
        "                'b':{'n_layer': 4, 'n_head': 4, 'n_embd': 128},\n",
        "                'a':{'n_layer': 3, 'n_head': 3, 'n_embd': 48}}\n",
        "\n",
        "        type_ = config.model_type is not None\n",
        "        #assert type_ in \"abcdefgh\"\n",
        "        p = all([config.n_layer is not None, config.n_head is not None, config.n_embd is not None])\n",
        "        #assert type_ == True and p == True\n",
        "        if type_:\n",
        "            config.merge_from_dict(self.model_states[config.model_type])\n",
        "        self.closs = nn.BCELoss()\n",
        "        self.ny = NY()\n",
        "        #self.l = nn.Linear(512,1,64)\n",
        "        self.transformer = nn.ModuleDict(dict(\n",
        "            wte = nn.Embedding(config.vocab_size, config.n_embd),\n",
        "            wpe = nn.Embedding(config.max_length, config.n_embd),\n",
        "            drop = nn.Dropout(config.embd_pdrop),\n",
        "            h = nn.ModuleList([Block(config) for _ in range(config.n_layer)]),\n",
        "            ln_f = nn.LayerNorm(config.n_embd),))\n",
        "        self.classifier_head = nn.Sequential(#nn.Tanh(),\n",
        "                                             nn.Linear(config.n_embd, 2)\n",
        "                                             )\n",
        "        self.apply(self._init_weights)\n",
        "        for pn, p in self.named_parameters():\n",
        "            if pn.endswith('c_proj.weight'):\n",
        "                torch.nn.init.normal_(p, mean=0.0, std=0.02/math.sqrt(2 * config.n_layer))\n",
        "\n",
        "        n_params = sum(p.numel() for p in self.transformer.parameters())\n",
        "        #print(\"[ Number of trainable parameters: %.2fM ]\" % (n_params/1e6,))\n",
        "\n",
        "    def _init_weights(self, module):\n",
        "        if isinstance(module, nn.Linear):\n",
        "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
        "            if module.bias is not None:\n",
        "                torch.nn.init.zeros_(module.bias)\n",
        "        elif isinstance(module, nn.Embedding):\n",
        "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
        "        elif isinstance(module, nn.LayerNorm):\n",
        "            torch.nn.init.zeros_(module.bias)\n",
        "            torch.nn.init.ones_(module.weight)\n",
        "\n",
        "    @classmethod\n",
        "    def from_pretrained(cls, model_type):\n",
        "        from transformers import GPT2LMHeadModel\n",
        "        config = cls.get_default_config()\n",
        "        config.model_type = model_type\n",
        "        config.vocab_size = 25\n",
        "        config.max_length = 512\n",
        "        model = ClassifierI(config)\n",
        "        sd = model.state_dict()\n",
        "        model_hf = GPT2LMHeadModel.from_pretrained(model_type)\n",
        "        sd_hf = model_hf.state_dict()\n",
        "        keys = [k for k in sd_hf if not k.endswith('attn.masked_bias')]\n",
        "        transposed = ['attn.c_attn.weight', 'attn.c_proj.weight', 'mlp.c_fc.weight', 'mlp.c_proj.weight']\n",
        "        assert len(keys) == len(sd)\n",
        "        for k in keys:\n",
        "            if any(k.endswith(w) for w in transposed):\n",
        "                assert sd_hf[k].shape[::-1] == sd[k].shape\n",
        "                with torch.no_grad():\n",
        "                    sd[k].copy_(sd_hf[k].t())\n",
        "            else:\n",
        "                assert sd_hf[k].shape == sd[k].shape\n",
        "                with torch.no_grad():\n",
        "                    sd[k].copy_(sd_hf[k])\n",
        "        return model\n",
        "\n",
        "    def configure_optimizers(self, train_config):\n",
        "        decay = set()\n",
        "        no_decay = set()\n",
        "        whitelist_weight_modules = (torch.nn.Linear, )\n",
        "        blacklist_weight_modules = (torch.nn.LayerNorm, torch.nn.Embedding)\n",
        "        for mn, m in self.named_modules():\n",
        "            for pn, p in m.named_parameters():\n",
        "                fpn = '%s.%s' % (mn, pn) if mn else pn\n",
        "                if pn.endswith('bias'):\n",
        "                    no_decay.add(fpn)\n",
        "                elif pn.endswith('weight') and isinstance(m, whitelist_weight_modules):\n",
        "                    decay.add(fpn)\n",
        "                elif pn.endswith('weight') and isinstance(m, blacklist_weight_modules):\n",
        "                    no_decay.add(fpn)\n",
        "        param_dict = {pn: p for pn, p in self.named_parameters()}\n",
        "        inter_params = decay & no_decay\n",
        "        union_params = decay | no_decay\n",
        "        assert len(inter_params) == 0, \"parameters %s made it into both decay/no_decay sets!\" % (str(inter_params), )\n",
        "        assert len(param_dict.keys() - union_params) == 0, \"parameters %s were not separated into either decay/no_decay set!\" \\\n",
        "                                                    % (str(param_dict.keys() - union_params), )\n",
        "        optim_groups = [\n",
        "            {\"params\": [param_dict[pn] for pn in sorted(list(decay))], \"weight_decay\": train_config.weight_decay},\n",
        "            {\"params\": [param_dict[pn] for pn in sorted(list(no_decay))], \"weight_decay\": 0.0},]\n",
        "        optimizer = torch.optim.AdamW(optim_groups, lr=train_config.learning_rate, betas=train_config.betas)\n",
        "        return optimizer\n",
        "\n",
        "    @torch.no_grad\n",
        "    def predict_proba(self,idx,j =\"None\"):\n",
        "      sigmoid = nn.Sigmoid()\n",
        "      soft = nn.Softmax(dim=1)\n",
        "      ny = NY()\n",
        "      si = SiLU()\n",
        "      self.eval()\n",
        "      x,_ = self.forward(idx)\n",
        "      if j == \"None\":\n",
        "        return x[:,0:1]\n",
        "      elif j == \"soft\":\n",
        "        return self.soft(x)[:,0:1]\n",
        "      else:\n",
        "        return sigmoid(x)[:,0:1]\n",
        "\n",
        "    @torch.no_grad\n",
        "    def predict(self,idx):\n",
        "      g = torch.zeros((idx.shape[0],1))\n",
        "      e = -1\n",
        "      for i in self.predict_proba(idx):\n",
        "        e+=1\n",
        "        if i[0].item()>=0.5:\n",
        "          g[e] = 1\n",
        "      return g\n",
        "\n",
        "    def forward(self, idx, targets=None):\n",
        "        device = idx.device\n",
        "        b, t = idx.size()\n",
        "        pos = torch.arange(0, t, dtype=torch.long, device=device).unsqueeze(0)\n",
        "        tok_emb = self.transformer.wte(idx)\n",
        "        pos_emb = self.transformer.wpe(pos)\n",
        "        x = self.transformer.drop(tok_emb + pos_emb)\n",
        "        for block in self.transformer.h:\n",
        "            x = block(x)\n",
        "        x = self.transformer.ln_f(x)\n",
        "        logits = self.ny(self.classifier_head(x)).mean(1).to(device)\n",
        "        #logits = self.l(logits)\n",
        "        # = F.sigmoid(logits.view(b,2).mean(1).view(b,1))\n",
        "        loss = None\n",
        "        if targets is not None:\n",
        "            loss = F.cross_entropy(logits,targets,ignore_index = -1)\n",
        "        return logits, loss\n",
        "\n",
        "\n",
        "class Trainer:\n",
        "    @staticmethod\n",
        "    def get_default_config():\n",
        "        C = CfgNode()\n",
        "        C.device = 'cuda'\n",
        "        C.num_workers = 4\n",
        "        C.max_iters = None\n",
        "        C.batch_size = 64\n",
        "        C.max_length = 512\n",
        "        C.learning_rate = 8e-4\n",
        "        C.betas = (0.9, 0.95)\n",
        "        C.weight_decay = 0.1\n",
        "        C.grad_norm_clip = 1.0\n",
        "        return C\n",
        "\n",
        "    def __init__(self, config, model, train_dataset,val_dataset):\n",
        "        self.config = config\n",
        "        self.model = model\n",
        "        self.optimizer = None\n",
        "        self.train_dataset = train_dataset\n",
        "        self.val_dataset = val_dataset\n",
        "        self.callbacks = defaultdict(list)\n",
        "        self.device ='cuda'\n",
        "        self.model = self.model.to(self.device)\n",
        "        self.iter_num = 0\n",
        "        self.iter_time = 0.0\n",
        "        self.iter_dt = 0.0\n",
        "\n",
        "    def add_callback(self, onevent: str, callback):\n",
        "        self.callbacks[onevent].append(callback)\n",
        "\n",
        "    def set_callback(self, onevent: str, callback):\n",
        "        self.callbacks[onevent] = [callback]\n",
        "\n",
        "    def trigger_callbacks(self, onevent: str):\n",
        "        for callback in self.callbacks.get(onevent, []):\n",
        "            callback(self)\n",
        "\n",
        "    def run(self):\n",
        "        model, config = self.model, self.config\n",
        "        self.optimizer = model.configure_optimizers(config)\n",
        "        batch_size = self.config.batch_size\n",
        "        def get_batch(mode):\n",
        "            batch_size = 64\n",
        "            if mode == \"train\":\n",
        "              data = train_dataset\n",
        "              pos_train = torch.tensor(np.array([data[i:i+1,:] for i in range(data.shape[0]) if data[i,-1].item() == 1]).reshape(len([data[i:i+1,:] for i in range(data.shape[0]) if data[i,-1].item() == 1]),513))\n",
        "              neg_train = torch.tensor(np.array([data[i:i+1,:] for i in range(data.shape[0]) if data[i,-1].item() == 0]).reshape(len([data[i:i+1,:] for i in range(data.shape[0]) if data[i,-1].item() == 0]),513))\n",
        "              N = np.random.randint(batch_size)\n",
        "              ix_pos = np.random.randint(pos_train.shape[0]-N)\n",
        "              ix_neg = np.random.randint(neg_train.shape[0]-batch_size-N)\n",
        "              pos_data = pos_train[ix_pos:ix_pos+N,:]\n",
        "              neg_data = neg_train[ix_neg:ix_neg+batch_size-N,:]\n",
        "              data = torch.concat((pos_data,neg_data))\n",
        "              seq = data[:,:-1]\n",
        "              targets = torch.zeros((batch_size,2), device=self.device)\n",
        "              o = -1\n",
        "              for i in data:\n",
        "                o+=1\n",
        "                if i[-1].item() == 1:\n",
        "                  targets[o][0] = 1\n",
        "                else:\n",
        "                  targets[o][1] = 1\n",
        "            else:\n",
        "              data = val_dataset\n",
        "              ix = np.random.randint(data.shape[0]-batch_size)\n",
        "              data = data[ix:ix+batch_size,:]\n",
        "              seq = data[:,:-1]\n",
        "              targets = torch.zeros((batch_size,2), device=self.device)\n",
        "              o = -1\n",
        "              for i in data:\n",
        "                o+=1\n",
        "                if i[-1].item() == 1:\n",
        "                  targets[o][0] = 1\n",
        "                else:\n",
        "                  targets[o][1] = 1\n",
        "            targets = targets.view(batch_size,2).to(self.device)\n",
        "            seq = seq.view(batch_size,512).to(self.device)\n",
        "            return seq, targets\n",
        "\n",
        "        @torch.no_grad\n",
        "        def cross_val():\n",
        "          model.eval()\n",
        "          out = []\n",
        "          for i in [\"train\",\"val\"]:\n",
        "            losses = torch.zeros(200+1)\n",
        "            for k in range(200):\n",
        "              X,Y = get_batch(i)\n",
        "              logits,loss = model(X,Y)\n",
        "              losses[k]=loss.item()\n",
        "              out1 = losses.mean()\n",
        "            out.append(out1)\n",
        "          model.train()\n",
        "          return out\n",
        "        losses = cross_val()\n",
        "        LOSS = [losses]\n",
        "        print(\"\\n[train loss = {k}, val loss =  {j}]\\n\".format(k = losses[0],j = losses[1]))\n",
        "        model.train()\n",
        "        for epoch in range(20):\n",
        "          print(\"[epoch {o}] \\n\".format(o = epoch))\n",
        "          iters = 200\n",
        "          for i in range(iters):\n",
        "            if i == 0:\n",
        "              Y = \"| =\"\n",
        "            elif i == iters -1 :\n",
        "              Y = \"=> 100% |\"\n",
        "            else:\n",
        "              if i%(int(iters/50)) == 0 :\n",
        "                Y = \"=\"\n",
        "              else:\n",
        "                Y = \"\"\n",
        "            print(\"{y}\".format(y = Y),end=\"\")\n",
        "            x, y = get_batch(\"train\")\n",
        "            logits, self.loss = model(x, y)\n",
        "            model.zero_grad(set_to_none=True)\n",
        "            self.loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), config.grad_norm_clip)\n",
        "            self.optimizer.step()\n",
        "          losses = cross_val()\n",
        "          LOSS.append(losses)\n",
        "          print(LOSS)\n",
        "          print(\"\\n[train loss = {k}, val loss =  {j}]\\n\".format(k = losses[0],j = losses[1]))\n",
        "        PATH = \"model {h}\".format(h = model_config.model_type)\n",
        "        torch.save(model.state_dict(), PATH)\n",
        "class Transformer():\n",
        "  def __init__(self,mode):\n",
        "    self.mode = mode\n",
        "    self.device = torch.device(\"cuda\")\n",
        "    self.vocab_dict = tokenizer.get_vocab()\n",
        "\n",
        "  def classifier(self):\n",
        "    device = self.device\n",
        "    model_config = ClassifierI.get_default_config()\n",
        "    model_config.vocab_size = 25\n",
        "    model_config.block_size = 512\n",
        "    if self.mode == \"b\":\n",
        "      model_config.model_type = 'b'\n",
        "      model2 = ClassifierI(model_config)\n",
        "      model2.load_state_dict(torch.load(\"classi/model_b\",map_location=self.device))\n",
        "    else:\n",
        "      model_config.model_type = 'c'\n",
        "      model2 = ClassifierI(model_config)\n",
        "      model2.load_state_dict(torch.load(\"classi/model_c\",map_location = self.device))\n",
        "    model2.to(device)\n",
        "    return model2\n",
        "\n",
        "  def Encode(self, i):\n",
        "        def encode_char(x):\n",
        "            return [self.vocab_dict[char] for char in x]\n",
        "\n",
        "        def pad_sequences(x, PAD=0, max_len=512):\n",
        "            return np.array([seq + [PAD] * (max_len - len(seq)) for seq in x])\n",
        "\n",
        "        encoded = list(map(encode_char, i))\n",
        "        padded = pad_sequences(encoded)\n",
        "        return torch.tensor(padded).to(self.device)\n",
        "\n",
        "  def Decode(self,i):\n",
        "    def decode(k):\n",
        "      l = [j for j in k if j != 0 ]\n",
        "      seq = [chars[j] for j in l]\n",
        "      return \"\".join(seq)\n",
        "    H = list(map(decode,i))\n",
        "    G = []\n",
        "    for i in H:\n",
        "      if len(i)>512:\n",
        "        u = H.index(i)\n",
        "        for j in range(len(i)-512):\n",
        "          G.append(i[j:j+512])\n",
        "      else:\n",
        "        G.append(i)\n",
        "    return G,u\n",
        "  def Mean(self,i):\n",
        "    I = list(i.ravel())\n",
        "    sig = lambda x:np.e**(0*x)\n",
        "    Sum = [sig(np.abs(x-int(len(I)/2))) for x in range(len(I))]\n",
        "    wei = np.array([Sum[i]/sum(Sum) for i in range(len(I))]).reshape(len(I),1)\n",
        "    return np.sum(wei*i)\n",
        "\n",
        "  def enhancer(self,x):\n",
        "    wei = np.array([np.exp((i[0]-1)/(i[0])) for i in x])\n",
        "    return np.sum(np.array([i[0] for i in x])*wei)/np.sum(wei)\n",
        "\n",
        "  def predict_proba(self,i):\n",
        "    if len(i[0])>512:\n",
        "       l = [self.Encode([i[0][j:j+512]]) for j in range(len(i[0])-512)]\n",
        "       if len(l)>700:\n",
        "        L = [torch.concat(tuple(l[i*700:(i+1)*700])) for i in range(len(l)//700)] + [torch.concat(tuple(l[(len(l)//700)*700:(len(l)//700)*700+len(l)%700]))]\n",
        "        T = [self.classifier().predict_proba(i,\"sig\").tolist() for i in L ]\n",
        "        return self.enhancer(np.concatenate(tuple([i for i in T])))\n",
        "       else:\n",
        "         t = torch.concat(tuple(l))\n",
        "         return self.enhancer(self.classifier().predict_proba(t,\"sig\").tolist())\n",
        "    else:\n",
        "       seq = self.Encode(i)\n",
        "       U = np.array(self.classifier().predict_proba(seq,\"sig\").tolist())\n",
        "       out = np.array(U)\n",
        "       return out.reshape(len(i),1)\n",
        "\n",
        "model2 = Transformer(\"b\")\n",
        "model3 = Transformer(\"c\")\n",
        "\n",
        "\n",
        "import functools as FUNC\n",
        "from numba import njit\n",
        "\n",
        "class PPA():\n",
        "    def __init__(self, seq, model):\n",
        "        self.model = model\n",
        "        self.seq = seq\n",
        "        self.len = len(self.seq)\n",
        "        self.idx = None\n",
        "\n",
        "    def attention_mask(self):\n",
        "        idx2 = self.splicer(self.seq)[1]\n",
        "        k = self.T()\n",
        "        mask = [[True if len(k[0]) > idx2[j] - i > -1 else False for i in range(len(k[j]))] for j in range(len(k))]\n",
        "        return mask\n",
        "\n",
        "    def mean(self, mask, spliced):\n",
        "        u = [np.mean(self.model.predict_proba([spliced[i][j] for j in range(len(spliced[i])) if mask[i][j]])) for i in trange(len(spliced))]\n",
        "        return u\n",
        "\n",
        "    def splice_scorer(self, i):\n",
        "        lmin = len(i) // 2\n",
        "        return [i[j:j + lmin] for j in range(len(i) - lmin + 1)]\n",
        "\n",
        "    def splicer(self, i):\n",
        "        idx = self.idx\n",
        "        o, Before = [], []\n",
        "        for j in range(len(i)):\n",
        "            n_b, n_a = j, len(i) - j - 1\n",
        "            if n_b <= idx // 2:\n",
        "                before = i[max(0, j - idx // 2):j]\n",
        "                after = i[j + 1:j + idx - len(before)]\n",
        "            elif n_a <= idx // 2:\n",
        "                before = i[j - idx + n_a + 1:j]\n",
        "                after = i[j + 1:]\n",
        "            else:\n",
        "                before = i[j - idx // 2:j]\n",
        "                after = i[j + 1:j + idx // 2 + 1]\n",
        "            o.append(before + i[j] + after)\n",
        "            Before.append(len(before))\n",
        "        return o, Before\n",
        "\n",
        "    def T(self):\n",
        "        return list(map(self.splice_scorer, self.splicer(self.seq)[0]))\n",
        "\n",
        "    def Out(self):\n",
        "        s = self.s\n",
        "        def d(x):\n",
        "            if s > 0.7:\n",
        "                return x * np.exp(-1.2 * (x - s))\n",
        "            else:\n",
        "                return x if x > 0.7 else x\n",
        "\n",
        "        return list(map(d, self.mean(self.attention_mask(), self.T())))\n",
        "def show(i):\n",
        "  values = np.array(i).reshape(1, len(i))\n",
        "  y = range(len(i))\n",
        "  Y = [(j,1) for j in range(len(i)) if np.mean([i[j],i[min((j+1),len(i)-1)],i[max(0,(j-1))]])>0.6]\n",
        "  Y2 = [(j,1) for j in range(len(i)) if np.mean([i[j],i[min((j+1),len(i)-1)],i[min((j+2),len(i)-1)],i[min((j+3),len(i)-1)],i[min((j+4),len(i)-1)],i[min((j+5),len(i)-1)],i[max(0,(j-1))],i[max(0,(j-2))],i[max(0,(j-3))],i[max(0,(j-4))],i[max(0,(j-5))]])>0.85]\n",
        "  threshold = 0.5\n",
        "  above_threshold = np.maximum(values - threshold, 0)\n",
        "  below_threshold = np.minimum(values, threshold)\n",
        "  fig, (ax3 , ax4) = plt.subplots(2,1,sharex = True,sharey = True)\n",
        "  ax3.bar(y, below_threshold.ravel(), 0.9, color=\"lightblue\")\n",
        "  ax3.bar(y, above_threshold.ravel(), 0.9, color=\"lightgreen\",\n",
        "               bottom=below_threshold.ravel())\n",
        "  ax4.broken_barh(Y, (0.7, 0.03),\n",
        "               facecolors=( 'red'))\n",
        "  ax4.plot([0., y[-1]],[0.715,0.715],\"-b\")\n",
        "  for k in Y:\n",
        "    ax4.plot([k[0],k[0]+1],[0.715,0.715],\"-r\")\n",
        "\n",
        "  ax4.text(0,0.8 , \"LLPS-susceptible regions\",fontsize = 20)\n",
        "  ax3.plot([0., y[-1]], [threshold, threshold], \"k--\")\n",
        "  ax4.set_ylim([0,1])\n",
        "  ax3.set_ylim([0,1])\n",
        "\n",
        "  plt.subplots_adjust(\n",
        "                    wspace=0.4,\n",
        "                    hspace=0)\n",
        "  fig.set_figwidth(20)\n",
        "  fig.set_figheight(15)\n",
        "  plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "_R4AYlL7PfO2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101,
          "referenced_widgets": [
            "9887b561461b47ccaf1c75a86496c259",
            "d42e26f75810496f99444f8ed31dbc82",
            "dc4ec4f6ad3743ef9a443d239fa47e53",
            "82e7ae2527e74436af3a409d58d03d10",
            "97c833b9ed884edd8b9a89016d82f91c",
            "4b17280ab68a4dd7910a38bcc47fb6a2",
            "d7968132a13049a8a040b3b490ed3dc5",
            "e5ef09c5c600401f92e7d0926758080a",
            "483050b2c01d481aaeefb6155a9e528a",
            "c5cf071e058644b8a215a83e8b87cc1c",
            "00623c962e814c1f9a0247ffe677e96b"
          ]
        },
        "cellView": "form",
        "outputId": "fc41dbff-0095-4f2b-8d0d-53f692864a6a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The request to the Slack API failed. (url: https://www.slack.com/api/chat.postMessage)\n",
            "The server responded with: {'ok': False, 'error': 'not_authed'}\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/702 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9887b561461b47ccaf1c75a86496c259"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Score : 0.8005271438551996\n"
          ]
        }
      ],
      "source": [
        "#@title Loading sequence , then hit `Runtime` -> `Run all`\n",
        "#@markdown - Load the sequence of your protein :\n",
        "Sequence = \"MAAAAEPRQEFEVMEDHAGTYGLGDRKDQGGYTMHQDQEGDTDAGLKESPLQTPTEDGSEEPGSETSDAKSTPTAEDVTAPLVDEGAPGKQAAAQPHTEIPEGTTAEEAGIGDTPSLEDEAAGHVTQARMVSKSKDGTGSDDKKAKGADGKTKIATPRGAAPPGQKGQANATRIPAKTPPAPKTPPSSGEPPKSGDRSGYSSPGSPGTPGSRSRTPSLPTPPTREPKKVAVVRTPPKSPSSAKSRLQTAPVPMPDLKNVKSKIGSTENLKHQPGGGKVQIINKKLDLSNVQSKCGSKDNIKHVPGGGSVQIVYKPVDLSKVTSKCGSLGNIHHKPGGGQVEVKSEKLDFKDRVQSKIGSLDNITHVPGGGNKKIETHKLTFRENAKAKTDHGAEIVYKSPVVSGDTSPRHLSNVSSTGSIDMVDSPQLATLADEVSASLAKQGLGAPGSAGSAAGSGMVSKGEELFTGVVPILVELDGDVNGHKFSVSGEGEGDATYGKLTLKFICTTGKLPVPWPTLVTTLTYGVQCFSRYPDHMKQHDFFKSAMPEGYVQERTIFFKDDGNYKTRAEVKFEGDTLVNRIELKGIDFKEDGNILGHKLEYNYNSHNVYIMADKQKNGIKVNFKIRHNIEDGSVQLADHYQQNTPIGDGPVLLPDNHYLSTQSKLSKDPNEKRDHMVLLEFVTAAGITLGMDELYKLEVLFQ\" #@param {type:\"string\"}\n",
        "ID = None #@param {type:\"string\"}\n",
        "Directory = None #@param {type:\"string\"}\n",
        "#@markdown  - Use `End_sequence` to focus the scoring on sequences up to the specified endpoint\n",
        "\n",
        "End_sequence = 15 #@param {type:\"slider\" , min : 0 , max: 1000 , step : 1}\n",
        "Plot = True #@param {type: \"boolean\"}\n",
        "\n",
        "#@markdown - Specify the path of `FASTA format file` of your sequences.\n",
        "Fasta_file = \"uniref_PHB_synthesis_2024_06_07.fasta\" #@param {type:\"string\"}\n",
        "import pandas as pd\n",
        "#assert [Sequence == None , Fasta_file == None].count(True) == 1\n",
        "\n",
        "def enh(x):\n",
        "  wei = np.array([np.exp((i-1)/(i)) for i in x])\n",
        "  return np.sum(np.array(x)*wei)/np.sum(wei)\n",
        "\n",
        "def edit(i):\n",
        "  for j in i:\n",
        "    if j in \"\\t\\nBJOUXZ, _@#$%^&*({}[])\":\n",
        "      i = i.replace(j,\"\")\n",
        "  return i\n",
        "\n",
        "if Sequence != None and Sequence !=\"\":\n",
        "  Sequence = edit(Sequence)\n",
        "\n",
        "  u = model3.predict_proba([Sequence])\n",
        "\n",
        "  c = PPA(Sequence,model3)\n",
        "  c.s = np.mean(u)\n",
        "  c.idx = min(50,int(np.ceil(0.1*len(Sequence))))\n",
        "  if Plot == True:\n",
        "    p = c.Out()\n",
        "    c.p = p\n",
        "    c.dir = Directory\n",
        "    c.name = ID\n",
        "    i = c.p\n",
        "    values = np.array(i).reshape(1, len(i))\n",
        "    below_threshold = [k if k<= 0.5 else 0.5 for k in i]\n",
        "    above_threshold = [0 if k<= 0.5 else k-0.5 for k in i]\n",
        "    threshold = 0.5\n",
        "    y = list(range(len(i)))\n",
        "    Y = [(j, 1) for j in range(len(i)) if np.mean([i[j], i[min((j + 1), len(i) - 1)], i[max(0, (j - 1))]]) > 0.6]\n",
        "    Y2 = [(j, 1) for j in range(len(i)) if np.mean([i[j], i[min((j + 1), len(i) - 1)], i[min((j + 2), len(i) - 1)],\n",
        "                                               i[min((j + 3), len(i) - 1)], i[min((j + 4), len(i) - 1)],\n",
        "                                               i[min((j + 5), len(i) - 1)], i[max(0, (j - 1))],\n",
        "                                               i[max(0, (j - 2))], i[max(0, (j - 3))], i[max(0, (j - 4))],\n",
        "                                               i[max(0, (j - 5))]]) > 0.85]\n",
        "    fig = make_subplots(rows=1, cols=1, shared_xaxes=True, shared_yaxes=True, vertical_spacing=0.02)\n",
        "    fig.add_trace(go.Bar(x=y, y=below_threshold, marker_color='lightblue', name='Below Threshold', width= 1.3), row=1, col=1)\n",
        "    fig.add_trace(go.Bar(x=y, y=above_threshold, marker_color='lightgreen', name='Above Threshold', base=below_threshold, width= 1.3), row=1, col=1)\n",
        "\n",
        "    fig.add_trace(go.Scatter(x=[0, len(i) - 1], y=[threshold, threshold], mode='lines', line=dict(color='black', dash='dash'), showlegend=False), row=1, col=1)\n",
        "    for start, duration in Y:\n",
        "        fig.add_trace(go.Scatter(x=[start, start + duration], y=[0.01, 0.01], mode='lines', line=dict(color='red', width=7), showlegend=False), row=1, col=1)\n",
        "    fig.update_layout(height=800, width=1700, title_text=\"LLPS Prediction Plot\")\n",
        "    score = str(((2*u+2*enh(p))/4))\n",
        "    print(\"Score : \"+score)\n",
        "  else:\n",
        "    score = u\n",
        "    print(\"Score : \"+str(score))\n",
        "\n",
        "\n",
        "else:\n",
        "  if os.path.exists(Fasta_file):\n",
        "    with open(Fasta_file) as f:\n",
        "      u = f.read().split(\">\")\n",
        "      w = len(u)\n",
        "\n",
        "    j = u[1:End_sequence+1]\n",
        "    D = {\"id\":[i[:i.index(\"\\n\")] if \"\\n\" in i else i for i in j],\"seq\":[edit(i[i.index(\"\\n\"):]) if \"\\n\" in i else None for i in j],\"score\":None}\n",
        "    D[\"score\"] = [i[0][0] if type(i) != np.float64 else i for i in  [model3.predict_proba([s]) for s in tqdm(D[\"seq\"])]]\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title plot\n",
        "if Plot == True:\n",
        "  fig.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 837
        },
        "cellView": "form",
        "id": "QXTbh0DQZm69",
        "outputId": "800ff006-6f30-4da1-aa69-adf024824fc8"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.24.1.min.js\"></script>                <div id=\"02ce67d0-32cb-4251-a11a-36e4c977f069\" class=\"plotly-graph-div\" style=\"height:800px; width:1700px;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"02ce67d0-32cb-4251-a11a-36e4c977f069\")) {                    Plotly.newPlot(                        \"02ce67d0-32cb-4251-a11a-36e4c977f069\",                        [{\"marker\":{\"color\":\"lightblue\"},\"name\":\"Below Threshold\",\"width\":1.3,\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500,501,502,503,504,505,506,507,508,509,510,511,512,513,514,515,516,517,518,519,520,521,522,523,524,525,526,527,528,529,530,531,532,533,534,535,536,537,538,539,540,541,542,543,544,545,546,547,548,549,550,551,552,553,554,555,556,557,558,559,560,561,562,563,564,565,566,567,568,569,570,571,572,573,574,575,576,577,578,579,580,581,582,583,584,585,586,587,588,589,590,591,592,593,594,595,596,597,598,599,600,601,602,603,604,605,606,607,608,609,610,611,612,613,614,615,616,617,618,619,620,621,622,623,624,625,626,627,628,629,630,631,632,633,634,635,636,637,638,639,640,641,642,643,644,645,646,647,648,649,650,651,652,653,654,655,656,657,658,659,660,661,662,663,664,665,666,667,668,669,670,671,672,673,674,675,676,677,678,679,680,681,682,683,684,685,686,687,688,689,690,691,692,693,694,695,696,697,698,699,700,701],\"y\":[0.15233097916010088,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.4432522000338298,0.5,0.5,0.4993146888840099,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.49540793583537746,0.4928201541534426,0.49247988619135985,0.4928219761470291,0.49177704020253055,0.4915306177920824,0.4887978188099025,0.4888694073315814,0.4890702974409868,0.4878431294348864,0.4872126632717365,0.5,0.5,0.5,0.5,0.48210304273716353,0.48137557182910046,0.48024719266770466,0.4995373653545125,0.48153446892438645,0.48395033268690046,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.47564804092930063,0.43084262721454364,0.4939400795809435,0.5,0.5,0.5,0.4992642486979985,0.49931504760640777,0.49929771410137136,0.49943824372731555,0.4993079264296218,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.4514995183570126,0.4520654767360623,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.45461667967981534,0.452112562460704,0.4527037197404041,0.3876660951910769,0.38795379544104575,0.4369594147861182,0.4983835249948701,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.4810285052773593,0.42011164511342025,0.4673827942052003,0.4675312094896188,0.46765070034631223,0.4784280129750424,0.47749161724534367,0.4775450274839297,0.5,0.5,0.5,0.5,0.5,0.5,0.4842975959737892,0.4838479942869569,0.47449276495326154,0.4754319085002961,0.47546418592296547,0.4751115052577972,0.4748361268214426,0.46823990688934536,0.468106925811544,0.4749487768115354,0.4750220090185357,0.47511055465292507,0.4749726587419843,0.4744535174616186,0.42750518991505043,0.42726662382507125,0.42696757370365285,0.4790886475065458,0.47897540489942203,0.4788365368407022,0.4150220392394688,0.34484301717356164,0.3446069693510322,0.34459519092625845,0.4153976371224037,0.4077917540980599,0.40767654738150083,0.47300868419014996,0.47299591392372364,0.4711244863022622,0.4714454162818511,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.46424180051085595,0.3981056298502228,0.42703780299460586,0.4271838268427725,0.4275533981048653,0.42785476870556266,0.4292965087012976,0.430149189056283,0.43059489373082965,0.36161361528692276,0.35884773226003747,0.28454486899293086,0.3531595472763522,0.354228324649347,0.35384925945255596,0.2813578939734543,0.28066832816357123,0.28038712351132944,0.28099252038977424,0.2848782035480453,0.28599094581483503,0.28466030123494523,0.28383206039751135,0.2836087859721704,0.28369042498217556,0.2831977193060438,0.2999238568677326,0.36538715861115084,0.33419904910384163,0.3979009154650525,0.3974000060418194,0.46327974754135337,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.462459217820112,0.4627842003950588,0.45867337239415795,0.45906494313685,0.45861005572581126,0.3922303768257679,0.3921937325420556,0.3922451545332115,0.3909360414302721,0.3198907486164683,0.3910040074055321,0.32161606535435444,0.32198260276888135,0.3218833050404419,0.24258372673632575,0.2415630959188953,0.24121460684504384,0.2405783771894323,0.24026031063290204,0.24003947405203518,0.2408655554253201,0.24072553555234674,0.24115081574724537,0.24027211540590376,0.23868278157411732,0.23910137387905292,0.23863270708401763,0.23904583970012483,0.3174322976570182,0.31712441920121537,0.31715868959703286,0.3175774639199082,0.3908676283213853,0.39055780653048194,0.3905452775050217,0.3896090410200847,0.3176164961808895,0.31627319327632525,0.31566350522243675,0.31559689118452844,0.31565217796729245,0.3156424164054825,0.3155157647156543,0.31588489003356157,0.31601292954117105,0.3162478510585133,0.3159081485838602,0.31614352946530166,0.316020861254503,0.3161773095956007,0.31701507828923464,0.3197862393401052,0.3198439095302418,0.319639598736222,0.24092190287602902,0.24128858156030658,0.24556869634311157,0.2453909844544498,0.15834563037617375,0.15815775266288032,0.15835874262955396,0.1591281382650514,0.2430152407400339,0.24335014134316674,0.24378201751779938,0.24372182359664704,0.24427096770326906,0.244606663049381,0.3241435305147719,0.3238943702000933,0.32384237786705256,0.323739585212961,0.32323637464035987,0.3230286878056355,0.32352281920604276,0.32369726822443623,0.32291780141651105,0.3926505243832738,0.39323533550607204,0.3939733982185425,0.3944255083461132,0.3941727264454197,0.39070315651348464,0.4574149590029807,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.45936180352119194,0.45955822436910837,0.45956408776675534,0.45974217543305473,0.46037079719685614,0.4607733077313098,0.4604788574787175,0.4601031665665812,0.46068477542723724,0.39425464379232883,0.3936336487165467,0.39380207088984437,0.3934727297437791,0.40650807878080875,0.406839164298197,0.33526687895230367,0.25798721292626325,0.17194685794877143,0.17125338050155886,0.172954987914641,0.17195381691756714,0.17317488800727873,0.17337457448427723,0.17480297517059026,0.17482630897997692,0.17589519352515628,0.17694415124969873,0.1782245190411978,0.1796824034790039,0.18126313112261166,0.1819953444981143,0.18338701424038942,0.18548673461514542,0.18901477303539369,0.1910788302915041,0.19467336948295855,0.1989940589658739,0.19979234709556512,0.20571239014118625,0.15148191067303593,0.14980951431259898,0.14966387710484882,0.15042030337945447,0.152993679202225,0.15436919883304398],\"type\":\"bar\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"base\":[0.15233097916010088,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.4432522000338298,0.5,0.5,0.4993146888840099,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.49540793583537746,0.4928201541534426,0.49247988619135985,0.4928219761470291,0.49177704020253055,0.4915306177920824,0.4887978188099025,0.4888694073315814,0.4890702974409868,0.4878431294348864,0.4872126632717365,0.5,0.5,0.5,0.5,0.48210304273716353,0.48137557182910046,0.48024719266770466,0.4995373653545125,0.48153446892438645,0.48395033268690046,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.47564804092930063,0.43084262721454364,0.4939400795809435,0.5,0.5,0.5,0.4992642486979985,0.49931504760640777,0.49929771410137136,0.49943824372731555,0.4993079264296218,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.4514995183570126,0.4520654767360623,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.45461667967981534,0.452112562460704,0.4527037197404041,0.3876660951910769,0.38795379544104575,0.4369594147861182,0.4983835249948701,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.4810285052773593,0.42011164511342025,0.4673827942052003,0.4675312094896188,0.46765070034631223,0.4784280129750424,0.47749161724534367,0.4775450274839297,0.5,0.5,0.5,0.5,0.5,0.5,0.4842975959737892,0.4838479942869569,0.47449276495326154,0.4754319085002961,0.47546418592296547,0.4751115052577972,0.4748361268214426,0.46823990688934536,0.468106925811544,0.4749487768115354,0.4750220090185357,0.47511055465292507,0.4749726587419843,0.4744535174616186,0.42750518991505043,0.42726662382507125,0.42696757370365285,0.4790886475065458,0.47897540489942203,0.4788365368407022,0.4150220392394688,0.34484301717356164,0.3446069693510322,0.34459519092625845,0.4153976371224037,0.4077917540980599,0.40767654738150083,0.47300868419014996,0.47299591392372364,0.4711244863022622,0.4714454162818511,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.46424180051085595,0.3981056298502228,0.42703780299460586,0.4271838268427725,0.4275533981048653,0.42785476870556266,0.4292965087012976,0.430149189056283,0.43059489373082965,0.36161361528692276,0.35884773226003747,0.28454486899293086,0.3531595472763522,0.354228324649347,0.35384925945255596,0.2813578939734543,0.28066832816357123,0.28038712351132944,0.28099252038977424,0.2848782035480453,0.28599094581483503,0.28466030123494523,0.28383206039751135,0.2836087859721704,0.28369042498217556,0.2831977193060438,0.2999238568677326,0.36538715861115084,0.33419904910384163,0.3979009154650525,0.3974000060418194,0.46327974754135337,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.462459217820112,0.4627842003950588,0.45867337239415795,0.45906494313685,0.45861005572581126,0.3922303768257679,0.3921937325420556,0.3922451545332115,0.3909360414302721,0.3198907486164683,0.3910040074055321,0.32161606535435444,0.32198260276888135,0.3218833050404419,0.24258372673632575,0.2415630959188953,0.24121460684504384,0.2405783771894323,0.24026031063290204,0.24003947405203518,0.2408655554253201,0.24072553555234674,0.24115081574724537,0.24027211540590376,0.23868278157411732,0.23910137387905292,0.23863270708401763,0.23904583970012483,0.3174322976570182,0.31712441920121537,0.31715868959703286,0.3175774639199082,0.3908676283213853,0.39055780653048194,0.3905452775050217,0.3896090410200847,0.3176164961808895,0.31627319327632525,0.31566350522243675,0.31559689118452844,0.31565217796729245,0.3156424164054825,0.3155157647156543,0.31588489003356157,0.31601292954117105,0.3162478510585133,0.3159081485838602,0.31614352946530166,0.316020861254503,0.3161773095956007,0.31701507828923464,0.3197862393401052,0.3198439095302418,0.319639598736222,0.24092190287602902,0.24128858156030658,0.24556869634311157,0.2453909844544498,0.15834563037617375,0.15815775266288032,0.15835874262955396,0.1591281382650514,0.2430152407400339,0.24335014134316674,0.24378201751779938,0.24372182359664704,0.24427096770326906,0.244606663049381,0.3241435305147719,0.3238943702000933,0.32384237786705256,0.323739585212961,0.32323637464035987,0.3230286878056355,0.32352281920604276,0.32369726822443623,0.32291780141651105,0.3926505243832738,0.39323533550607204,0.3939733982185425,0.3944255083461132,0.3941727264454197,0.39070315651348464,0.4574149590029807,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.45936180352119194,0.45955822436910837,0.45956408776675534,0.45974217543305473,0.46037079719685614,0.4607733077313098,0.4604788574787175,0.4601031665665812,0.46068477542723724,0.39425464379232883,0.3936336487165467,0.39380207088984437,0.3934727297437791,0.40650807878080875,0.406839164298197,0.33526687895230367,0.25798721292626325,0.17194685794877143,0.17125338050155886,0.172954987914641,0.17195381691756714,0.17317488800727873,0.17337457448427723,0.17480297517059026,0.17482630897997692,0.17589519352515628,0.17694415124969873,0.1782245190411978,0.1796824034790039,0.18126313112261166,0.1819953444981143,0.18338701424038942,0.18548673461514542,0.18901477303539369,0.1910788302915041,0.19467336948295855,0.1989940589658739,0.19979234709556512,0.20571239014118625,0.15148191067303593,0.14980951431259898,0.14966387710484882,0.15042030337945447,0.152993679202225,0.15436919883304398],\"marker\":{\"color\":\"lightgreen\"},\"name\":\"Above Threshold\",\"width\":1.3,\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500,501,502,503,504,505,506,507,508,509,510,511,512,513,514,515,516,517,518,519,520,521,522,523,524,525,526,527,528,529,530,531,532,533,534,535,536,537,538,539,540,541,542,543,544,545,546,547,548,549,550,551,552,553,554,555,556,557,558,559,560,561,562,563,564,565,566,567,568,569,570,571,572,573,574,575,576,577,578,579,580,581,582,583,584,585,586,587,588,589,590,591,592,593,594,595,596,597,598,599,600,601,602,603,604,605,606,607,608,609,610,611,612,613,614,615,616,617,618,619,620,621,622,623,624,625,626,627,628,629,630,631,632,633,634,635,636,637,638,639,640,641,642,643,644,645,646,647,648,649,650,651,652,653,654,655,656,657,658,659,660,661,662,663,664,665,666,667,668,669,670,671,672,673,674,675,676,677,678,679,680,681,682,683,684,685,686,687,688,689,690,691,692,693,694,695,696,697,698,699,700,701],\"y\":[0,0.2877489352344743,0.3853924943913747,0.3069291474336685,0.2356302676247215,0.18241959810036834,0.2703126617310515,0.3219537639211114,0.35372504913823843,0.3742946412740775,0.3589097414967126,0.3347787919445784,0.3106460938606572,0.2876210133840795,0.31373914720522533,0.33358200560689255,0.34927296142890785,0.3387939050331943,0.3239876882110756,0.31344354366871496,0.3289788192462697,0.34093547677961533,0.3322775473486339,0.34379688055176094,0.3406482602998008,0.350399658294549,0.3504090210486227,0.35278007282590995,0.3530724047228886,0.37080664215484904,0.3854969737973397,0.38486847962648785,0.37038199436418073,0.3530385996774539,0.3325889226269235,0.3241051026734234,0.3418223601458926,0.36091184020068634,0.37742052704521545,0.39106527701863525,0.3775717382672972,0.3614498777186932,0.3615577483183239,0.37260181595162123,0.38662040014906307,0.384707164537325,0.36995202509267344,0.36990007938902825,0.3682882882041434,0.3504176510094956,0.3430166135655466,0.3210922890890442,0.32186705195850684,0.3028020704987012,0.2760925527439355,0.2760583638081663,0.2455686477221264,0.27727014762261637,0.2807482683073882,0.28046677182820134,0.2810523985699209,0.29150858870168983,0.29117537013261685,0.2618888294101852,0.22807167503235815,0.1920216836931543,0.2280719414089919,0.2276723473186837,0.22569761098093155,0.2213563409710384,0.18298979435015084,0.1826650329474787,0.18252291661512965,0.14158578988045611,0.14168861093832896,0.14131881430031024,0.18292434703970928,0.21945696040933282,0.2183348767463109,0.2143409327472604,0.21233003802288697,0.1723507059456485,0.17060968661948217,0.17056820561081365,0.16552842365013398,0.20554699607084004,0.2042233789744925,0.20434005831490898,0.1658742168292926,0.1659493139293411,0.16728020232217244,0.16525983637803965,0.12150493325229506,0.12150313167063898,0.0749679455208101,0.03647949351081836,0.036801519550956674,0.036580654477633145,0.03604682487606914,0.03612033883047827,0.08603690802785402,0.1088066481737695,0.059157513365189485,0.006035449356724398,0.006147197891370859,0.0108023307969346,0.01101105695392246,0.05743045701368299,0.06148729690460053,0.0049370363475276235,0.003912819877434637,0.003851057910998379,0.0048555426309481176,0,0.0016294643320353686,0.0010505281038221126,0,0.05520487181394884,0.05524373287045514,0.05610660181754146,0.05550051652531529,0.10597483374997851,0.1517949701083332,0.15189663900772532,0.15183527307531597,0.15152097233626216,0.1510195352235134,0.16581945107039864,0.20576085176100978,0.20523621692210148,0.20510515707486499,0.19730628886516577,0.19755979488674436,0.16434152224892695,0.16156642814371014,0.20140506751300868,0.20164946013511864,0.16167154218857827,0.1612749094530268,0.2015011241630391,0.16123485354267053,0.20201675415195308,0.20611757449627477,0.2065896242223333,0.2380266573239992,0.27008490239320526,0.29871929409492504,0.27034525474805193,0.2694232817387716,0.2981027479747921,0.29823053476325834,0.29826199614848725,0.26976368578961485,0.2441687185017174,0.20847953814692222,0.20860750524318694,0.20936836955208438,0.24487941319180206,0.24501420724108258,0.24479224645803865,0.2522654370545794,0.25325542129019996,0.2837650995054014,0.31034489178187785,0.31032221439461305,0.3084386311388829,0.3323767596044266,0.33251214294648257,0.33014641814736334,0.30705275218332073,0.2834746470695301,0.2528390181481288,0.21865504689219406,0.21903953675621168,0.22061238636888347,0.2205679789600229,0.22101124908507863,0.2506024740403624,0.2817663818371121,0.3090102983881692,0.3329022898394597,0.35348180883101055,0.3536764858346746,0.3537741717750149,0.3712290137480019,0.3860042233587522,0.3955929327609061,0.395629452501573,0.3957629288795721,0.3957371948246534,0.40594769239180717,0.4067356562583325,0.397039829298655,0.3971240787312783,0.4070833071358876,0.40683935129990845,0.4145397671056418,0.4201601874631766,0.42381658760675467,0.4238538733806735,0.4202938041308878,0.42031526454538637,0.42390431123370476,0.42429418361529336,0.42250600544725836,0.4225036404276893,0.4182435633454179,0.41186073321471284,0.41806600302836805,0.41803166044802864,0.4115205826439351,0.4032710956669757,0.39234903291901346,0.37882928005719063,0.3629389863538496,0.3441641669441593,0.3219620858848403,0.2964166804489382,0.29600635827986754,0.2682372809918635,0.26815451200687956,0.26801371335048474,0.23562279963063848,0.19899604986419372,0.17012993332489457,0.20764894254536137,0.2067594054780355,0.16641102438147415,0.1211005119412546,0.07427307273522099,0.05251433551303475,0,0,0,0,0,0,0,0,0,0,0,0.04437398321489716,0.04428144967046377,0.04356115837834085,0.04056006856072547,0,0,0,0,0,0,0.041658128747855794,0.09392084872728446,0.09410643729421442,0.09053931751616706,0.12789493161190157,0.12765488033542483,0.12756384771777451,0.12768716379107414,0.07835392049449474,0.025147983957030218,0.024935244458842987,0.07931983771830198,0.07890197041258995,0.07879015081049645,0.07941928327024517,0.07924805208378993,0.02572717692356563,0.0261328936632359,0.026205495887643204,0.032509762844858514,0.08608569133287214,0.13463234969347648,0.1350837930688703,0.16427284168952538,0.19336129323614293,0.1514717919693216,0.10485295050724674,0.05368053429705766,0.05350006359617676,0.10231424982071291,0.06274701362253532,0.06268218231313682,0.06259652565006135,0.06229927757373488,0.062327021210382916,0.06192257333916018,0.06214372392681122,0.006059087891474024,0.06185686420079006,0.061637498251779776,0.06169355801601706,0.06167456779117131,0.11261144444721416,0.1121114127711702,0.11244703131875433,0.13594447407312893,0.08751333642434644,0.034016348471928026,0.03416068753560664,0,0,0,0.05154514988087755,0.05172862285202373,0.05285890601526577,0,0,0,0,0,0.004300130555737525,0.00474643893191673,0.06098191035518774,0.06082035333132052,0.00508199047449609,0.005431049183559744,0.012053850250047016,0.01252521618338942,0,0,0.0083624236933032,0.019844741979610836,0.02017132127689303,0.07526338278900047,0.07454010526561361,0.07509781537322835,0.12467740196922061,0.07508070866996142,0.02003792895354306,0.07383107453395565,0.0766494826200218,0.08098397933788704,0.12947042382585405,0.17387721279671087,0.21347436294989497,0.21391767622850122,0.24522031539154487,0.2449690077249631,0.20912078011563418,0.20967723247446335,0.20964090092751475,0.20961813615103686,0.20483852317658457,0.20452281752461587,0.20413567521735176,0.20389065654281135,0.16628406602221557,0.1311286186781867,0.13087620677538592,0.08214728736528554,0.08233333151658095,0.12861062258334766,0.0793791310975075,0.07946315836115858,0.07933471394959346,0.07895951739108342,0.07500938457876438,0.0705537659550457,0.015895633092995687,0,0,0,0,0,0,0,0.055341751327883104,0.10445897391182357,0.10458340705376357,0.10473923144817843,0.10507384396177977,0.10509608514050295,0.10606172245298451,0.10558727505343024,0.10559464073679647,0.10538279493817526,0.14888718018415104,0.10433984738877289,0.10417114043266418,0.12968249912439267,0.1635358867875073,0.11957822481021552,0.1268154306510717,0.12765577863773037,0.12758023601405977,0.12779702484876598,0.08061408165844741,0.08489623953960557,0.08529387815425493,0.12742752285277326,0.09234543264558404,0.03955246126052481,0,0,0,0,0,0,0,0,0.03630332478014797,0.08920954719737162,0.03971377299956258,0.03971928521850676,0.03981110224619011,0.02849959332602159,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0.030722070235163046,0.08464095935661098,0.13362750888493957,0.17623769050026072,0.13561340551203538,0.17943035514500738,0.1794613352605542,0.21862824350512233,0.2512441736742921,0.28199071733425063,0.2822322664376854,0.28609954696912965,0.2561361081334079,0.25619014873771095,0.25640131370710384,0.28459770524439454,0.31151758884196956,0.31183894187319916,0.31179138153533614,0.2847904988601141,0.28175102658676554,0.2818114562334715,0.2818701552596238,0.2835719105821062,0.28355832613591236,0.2833709506375761,0.279550536436747,0.27809787948663167,0.2779678609699737,0.24719066361018405,0.24577834678125832,0.2100489635617383,0.20973078544979817,0.1694103837152171,0.12865706298676627,0.0798662231198265,0.12831118622995263,0.12399561312498297,0.16870880179225656,0.1686917985203179,0.1683094585353644,0.12699610354697588,0.12440798454996749,0.12471024736029201,0.12513694677082776,0.12548371476464926,0.12020907229053635,0.1199867428087601,0.07038468791354724,0.06780636923579164,0.06821946944761981,0.06863448557523055,0.02124902577878751,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0.022073602500740752,0.020255593637269143,0.022107019139179007,0.02225401548113759,0.07541507659842617,0.12097221405214298,0.12582114143689582,0.13421880116093787,0.17781051498137257,0.1780261080015868,0.17771373106139665,0.17752308706271558,0.17729276656589243,0.21432827541570876,0.21366358023340215,0.2163944083769873,0.21625829495092153,0.21626018248559853,0.2507290886473935,0.25072386233314015,0.24343308076358738,0.21300867118229128,0.24763694084319787,0.2169694285340169,0.2506319755143376,0.2155879352571246,0.1764331567118408,0.21555701572832953,0.21454000422842112,0.2145974151187241,0.17628366677183693,0.13524885151647892,0.08654707331410738,0.07648350879185217,0.021693402684461516,0.02120554911757455,0.02160360523723337,0.022473346728871135,0.022150797627196517,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0.01752422902176798,0.07310079986821272,0.07343583600090475,0.0733463960526568,0.01945623730488444,0.019252174211014883,0.01968929788041629,0.019671664237141395,0.019961695498206145,0.019722282353790033,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],\"type\":\"bar\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"black\",\"dash\":\"dash\"},\"mode\":\"lines\",\"showlegend\":false,\"x\":[0,701],\"y\":[0.5,0.5],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[1,2],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[2,3],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[3,4],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[4,5],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[5,6],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[6,7],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[7,8],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[8,9],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[9,10],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[10,11],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[11,12],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[12,13],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[13,14],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[14,15],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[15,16],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[16,17],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[17,18],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[18,19],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[19,20],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[20,21],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[21,22],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[22,23],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[23,24],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[24,25],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[25,26],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[26,27],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[27,28],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[28,29],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[29,30],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[30,31],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[31,32],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[32,33],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[33,34],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[34,35],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[35,36],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[36,37],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[37,38],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[38,39],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[39,40],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[40,41],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[41,42],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[42,43],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[43,44],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[44,45],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[45,46],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[46,47],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[47,48],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[48,49],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[49,50],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[50,51],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[51,52],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[52,53],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[53,54],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[54,55],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[55,56],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[56,57],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[57,58],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[58,59],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[59,60],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[60,61],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[61,62],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[62,63],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[63,64],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[64,65],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[65,66],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[66,67],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[67,68],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[68,69],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[69,70],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[70,71],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[71,72],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[72,73],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[73,74],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[74,75],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[75,76],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[76,77],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[77,78],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[78,79],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[79,80],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[80,81],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[81,82],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[82,83],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[83,84],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[84,85],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[85,86],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[86,87],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[87,88],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[88,89],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[89,90],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[90,91],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[91,92],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[92,93],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[93,94],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[121,122],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[122,123],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[123,124],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[124,125],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[125,126],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[126,127],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[127,128],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[128,129],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[129,130],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[130,131],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[131,132],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[132,133],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[133,134],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[134,135],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[135,136],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[136,137],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[137,138],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[138,139],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[139,140],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[140,141],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[141,142],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[142,143],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[143,144],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[144,145],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[145,146],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[146,147],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[147,148],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[148,149],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[149,150],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[150,151],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[151,152],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[152,153],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[153,154],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[154,155],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[155,156],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[156,157],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[157,158],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[158,159],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[159,160],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[160,161],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[161,162],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[162,163],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[163,164],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[164,165],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[165,166],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[166,167],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[167,168],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[168,169],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[169,170],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[170,171],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[171,172],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[172,173],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[173,174],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[174,175],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[175,176],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[176,177],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[177,178],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[178,179],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[179,180],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[180,181],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[181,182],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[182,183],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[183,184],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[184,185],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[185,186],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[186,187],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[187,188],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[188,189],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[189,190],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[190,191],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[191,192],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[192,193],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[193,194],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[194,195],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[195,196],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[196,197],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[197,198],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[198,199],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[199,200],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[200,201],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[201,202],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[202,203],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[203,204],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[204,205],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[205,206],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[206,207],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[207,208],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[208,209],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[209,210],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[210,211],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[211,212],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[212,213],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[213,214],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[214,215],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[215,216],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[216,217],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[217,218],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[218,219],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[219,220],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[220,221],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[221,222],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[222,223],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[223,224],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[224,225],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[225,226],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[226,227],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[227,228],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[228,229],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[255,256],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[256,257],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[257,258],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[258,259],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[259,260],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[273,274],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[274,275],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[275,276],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[276,277],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[277,278],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[278,279],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[295,296],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[296,297],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[297,298],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[334,335],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[335,336],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[336,337],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[337,338],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[338,339],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[339,340],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[340,341],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[341,342],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[342,343],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[343,344],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[344,345],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[345,346],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[346,347],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[347,348],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[348,349],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[349,350],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[350,351],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[370,371],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[371,372],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[372,373],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[373,374],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[374,375],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[375,376],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[376,377],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[377,378],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[378,379],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[379,380],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[380,381],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[381,382],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[382,383],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[383,384],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[384,385],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[385,386],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[386,387],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[387,388],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[391,392],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[441,442],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[442,443],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[443,444],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[444,445],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[445,446],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[446,447],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[447,448],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[448,449],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[449,450],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[450,451],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[451,452],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[452,453],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[453,454],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[454,455],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[455,456],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[456,457],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[457,458],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[458,459],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[459,460],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[460,461],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[461,462],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[462,463],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[463,464],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[464,465],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[465,466],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[466,467],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[467,468],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[468,469],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[469,470],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[470,471],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[471,472],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[472,473],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[473,474],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[474,475],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[475,476],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[476,477],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[477,478],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[478,479],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[479,480],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[480,481],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[481,482],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[482,483],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[483,484],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[484,485],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[485,486],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[486,487],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[529,530],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[530,531],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[531,532],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[532,533],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[533,534],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[534,535],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[535,536],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[536,537],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[537,538],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[538,539],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[539,540],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[540,541],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[541,542],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[542,543],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[543,544],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[544,545],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[545,546],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[546,547],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[547,548],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[548,549],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[549,550],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[550,551],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[551,552],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[552,553],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[553,554],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[554,555],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"line\":{\"color\":\"red\",\"width\":7},\"mode\":\"lines\",\"showlegend\":false,\"x\":[555,556],\"y\":[0.01,0.01],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0]},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0]},\"title\":{\"text\":\"LLPS Prediction Plot\"},\"height\":800,\"width\":1700},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('02ce67d0-32cb-4251-a11a-36e4c977f069');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "metadata": {
        "cellView": "form",
        "id": "1xeTkJCtV0Wt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "88ac9439-d0c9-4999-daf8-f93edf3a984b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files zipped successfully!\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_78bff8c2-30de-4bef-8a8f-6d418a80259f\", \"zipped_files.zip\", 9155)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "#@title Downloading the results`\n",
        "\n",
        "if os.path.exists(\"d\"):\n",
        "    !rm -rf \"d\"\n",
        "if os.path.exists(\"text_dir\"):\n",
        "    !rm -rf \"text_dir\"\n",
        "\n",
        "!mkdir text_dir\n",
        "!mkdir d\n",
        "\n",
        "if Sequence != None and Sequence !=\"\" :\n",
        "  if c.name == None:\n",
        "    c.name = \"Your peptide\"\n",
        "  with open(\"seq.txt\",\"w\") as w:\n",
        "          w.write(\"                                                 <<<<<<  LLPS prediction results  >>>>>>\\n\\n\\n\")\n",
        "          w.write(\"[Sequence id] : \" +c.name+\"\\n\\n\")\n",
        "          w.write(\"[Sequence length] : \"+str(len(c.seq))+\"\\n\\n\")\n",
        "          w.write(\"[Sequence_of_peptide] : \" +c.seq+\"\\n\\n\")\n",
        "          w.write(\"[Predicted_score] : \" +score +\"\\n\\n\")\n",
        "          w.close()\n",
        "\n",
        "\n",
        "\n",
        "  if c.name != None:\n",
        "    img_name = \"Info_of_sequenceID:\"+c.name+\".png\"\n",
        "    fig.write_image(img_name)\n",
        "  else:\n",
        "    name = np.random.randint(1000000)\n",
        "    img_name = \"Info_of_sequenceID:\"+str(name)+\".png\"\n",
        "    fig.write_image(img_name)\n",
        "\n",
        "  shutil.move(img_name, \"d\")\n",
        "  shutil.move(\"seq.txt\", \"text_dir\")\n",
        "  text_files_path = \"text_dir\"\n",
        "  png_files_path = \"d\"\n",
        "\n",
        "  zip_output_path = 'zipped_files.zip'\n",
        "\n",
        "  text_files = [f for f in os.listdir(text_files_path) if f.endswith('.txt')]\n",
        "  png_files = [f for f in os.listdir(png_files_path) if f.endswith('.png')]\n",
        "\n",
        "  with zipfile.ZipFile(zip_output_path, 'w') as zipf:\n",
        "    for text_file in text_files:\n",
        "      zipf.write(os.path.join(text_files_path, text_file), arcname=text_file)\n",
        "\n",
        "    for png_file in png_files:\n",
        "      zipf.write(os.path.join(png_files_path, png_file), arcname=png_file)\n",
        "\n",
        "  print(\"Files zipped successfully!\")\n",
        "\n",
        "\n",
        "else:\n",
        "  h = pd.DataFrame(D)\n",
        "  h.to_json(\"h.json\")\n",
        "  with open(\"results.txt\",\"w\") as w:\n",
        "    w.write(\"                                                 <<<<<<  LLPS prediction results  >>>>>>\\n\\n\\n\")\n",
        "    w.write(\"Number of sequences : \"+str(len(D[\"seq\"]))+\"\\n\\n\")\n",
        "    for i in range(len(D[\"id\"])):\n",
        "      w.write(\" [Sequence {i}]\".format(i = i)+\"\\n\\n\")\n",
        "      w.write(\"   Sequence id : \"+D[\"id\"][i]+\"\\n\\n\")\n",
        "      w.write(\"   Sequence length : \"+str(len(D[\"seq\"][i]))+\"\\n\\n\")\n",
        "      w.write(\"   Sequence : \" + D[\"seq\"][i]+\"\\n\\n\")\n",
        "      w.write(\"   Predicted Score : \" + str(D[\"score\"][i])+\"\\n\\n\")\n",
        "      w.write(\"-\"*150+\"\\n\\n\")\n",
        "    w.close()\n",
        "    shutil.move(\"h.json\", \"d\")\n",
        "    shutil.move(\"results.txt\", \"text_dir\")\n",
        "    text_files_path = \"text_dir\"\n",
        "    png_files_path = \"d\"\n",
        "    zip_output_path = 'zipped_files.zip'\n",
        "\n",
        "    text_files = [f for f in os.listdir(text_files_path) if f.endswith('.txt')]\n",
        "    png_files = [f for f in os.listdir(png_files_path) if f.endswith('.json')]\n",
        "\n",
        "    with zipfile.ZipFile(zip_output_path, 'w') as zipf:\n",
        "      for text_file in text_files:\n",
        "        zipf.write(os.path.join(text_files_path, text_file), arcname=text_file)\n",
        "\n",
        "      for png_file in png_files:\n",
        "        zipf.write(os.path.join(png_files_path, png_file), arcname=png_file)\n",
        "\n",
        "    print(\"Files zipped successfully!\")\n",
        "\n",
        "files.download(\"zipped_files.zip\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##NCBI BLAST+\n",
        "To determine the BLAST database, you can either provide a FASTA file path to create your own database or use the URL link to NCBI's protein databases available on the NCBI page: https://ftp.ncbi.nlm.nih.gov/blast/db/\n",
        "\n",
        "The DrLLPS database has already been provided. By setting the Blast_Database to DrLLPS, the BLAST search will be conducted against the DrLLPS database.\n",
        "\n",
        "To load your sequences, you can either input a single sequence or upload a FASTA format file containing your sequences into the designated box\n",
        "\n",
        "as example :\n",
        "  **MAVRVAKMTEREKLLLKKYGNRRLYDTKRSAYVTLSQVADIIKQGVDVEVVDAKTQEDVTAFILTQIVLEQARRKNALLPAELLHLIIRYGEDLLQEFFQKYLEQTIHGYIQFKKAMDEQFSKWIDMQLNYSDMAHKTLSGLTRFPNIFSPPPGSPGTKKDKG**\n",
        "\n",
        "or\n",
        "\n",
        "**Your_file.fasta**\n",
        "\n"
      ],
      "metadata": {
        "id": "N1t2f4GlUJ7_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title BLAST+ Tool\n",
        "\n",
        "\n",
        "import os\n",
        "#@markdown - Specify the sequence or the path of your FASTA format file in this box : like  `MAVRVAKMTEREKLL`  or `Your_file.fasta`\n",
        "\n",
        "Sequence = \"MAVRVAKMTEREKLLLKKYGNRRLYDTKRSAYVTLSQVADIIKQGVDVEVVDAKTQEDVTAFILTQIVLEQARRKNALLPAELLHLIIRYGEDLLQEFFQKYLEQTIHGYIQFKKAMDEQFSKWIDMQLNYSDMAHKTLSGLTRFPNIFSPPPGSPGTKKDKG\" #@param {type:\"string\"}\n",
        "#@markdown - Specify the fasta file or URL of your Database here :                    like  `https://ftp.ncbi.nlm.nih.gov/blast/db/swissprot.tar.gz`  or `Your_Database.fasta`\n",
        "\n",
        "Blast_Database = \"DrLLPS\" #@param [\"DrLLPS\",\"https://ftp.ncbi.nlm.nih.gov/blast/db/FASTA/swissprot.gz\"] {allow-input : true}\n",
        "Blast_result_format = \"1\" #@param [1,2,3,4,5,6,7]\n",
        "Blast_result_file_name = \"result.txt\" #@param {type:\"string\"}\n",
        "E_value_threshold = \"100\" #@param {type:\"string\"}\n",
        "Max_target_Sequences = 4 #@param {type:\"integer\"}\n",
        "\n",
        "if Blast_Database == \"DrLLPS\":\n",
        "  Blast_Database = \"DrLLPS.fasta\"\n",
        "\n",
        "import sys\n",
        "from os import path\n",
        "\n",
        "if path.exists(\"/content/bioinformatics_stockholm/\"):\n",
        "  pass\n",
        "else:\n",
        "  !git clone https://github.com/Intertangler/bioinformatics_stockholm\n",
        "sys.path.insert(0,'/content')\n",
        "\n",
        "import importlib.util\n",
        "spec = importlib.util.spec_from_file_location(\"msa\", \"/content/bioinformatics_stockholm/msa/msa.py\")\n",
        "msa = importlib.util.module_from_spec(spec)\n",
        "spec.loader.exec_module(msa)\n",
        "\n",
        "spec = importlib.util.spec_from_file_location(\"miniblast\", \"/content/bioinformatics_stockholm/Miniblast/miniblast.py\")\n",
        "miniblast = importlib.util.module_from_spec(spec)\n",
        "spec.loader.exec_module(miniblast)\n",
        "\n",
        "def Fasta(fasta_path):\n",
        "  from command_runner import command_runner\n",
        "  command = \"makeblastdb -in {k} -dbtype prot -out blastdb\".format(k =fasta_path )\n",
        "  exit_code, output = command_runner(command, shell=True, live_output=True)\n",
        "  print(\"-- Blast Database has been created -- \\n\")\n",
        "\n",
        "\n",
        "if \".fasta\" in Blast_Database or \".txt\" in Blast_Database:\n",
        "  if os.path.exists(Blast_Database):\n",
        "    Fasta(Blast_Database)\n",
        "  with open(Blast_Database) as w:\n",
        "    j = w.read().split(\">\")[1:]\n",
        "  Dict = {i[:i.index(\"\\n\")].split(\" \")[0] if \"\\n\" in i else i : edit(i[i.index(\"\\n\"):]) if \"\\n\" in i else None for i in j}\n",
        "\n",
        "else:\n",
        "  command = \"wget {k}\".format(k = Blast_Database)\n",
        "  exit_code, output = command_runner(command, shell=True, live_output=True)\n",
        "  print(\"-- Blast Database has been downloaded -- \\n\")\n",
        "  exit_code, output = command_runner(\"gunzip {l}\".format(l = Blast_Database.split(\"/\")[-1]), shell=True, live_output=True)\n",
        "  Fasta(Blast_Database.split(\"/\")[-1][:-3])\n",
        "  db = miniblast.read_database_fasta(Blast_Database.split(\"/\")[-1][:-3])\n",
        "  Dict = {i.id :\"\".join(list(i.seq)) for i in db}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "HC5GzDMDCOgN",
        "outputId": "36fc4a52-6318-4bc4-a551-946e2d297aaf"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Building a new DB, current time: 06/07/2024 16:12:34\n",
            "New DB name:   /content/blastdb\n",
            "New DB title:  DrLLPS.fasta\n",
            "Sequence type: Protein\n",
            "Keep MBits: T\n",
            "Maximum file size: 1000000000B\n",
            "Adding sequences from FASTA; added 1272 sequences in 0.0319388 seconds.\n",
            "\n",
            "\n",
            "-- Blast Database has been created -- \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Blast Result\n",
        "\n",
        "blosum62 = {\n",
        "    ('W', 'F'): 1, ('L', 'R'): -2, ('S', 'P'): -1, ('V', 'T'): 0,\n",
        "    ('Q', 'Q'): 5, ('N', 'A'): -2, ('Z', 'Y'): -2, ('W', 'R'): -3,\n",
        "    ('Q', 'A'): -1, ('S', 'D'): 0, ('H', 'H'): 8, ('S', 'H'): -1,\n",
        "    ('H', 'D'): -1, ('L', 'N'): -3, ('W', 'A'): -3, ('Y', 'M'): -1,\n",
        "    ('G', 'R'): -2, ('Y', 'I'): -1, ('Y', 'E'): -2, ('B', 'Y'): -3,\n",
        "    ('Y', 'A'): -2, ('V', 'D'): -3, ('B', 'S'): 0, ('Y', 'Y'): 7,\n",
        "    ('G', 'N'): 0, ('E', 'C'): -4, ('Y', 'Q'): -1, ('Z', 'Z'): 4,\n",
        "    ('V', 'A'): 0, ('C', 'C'): 9, ('M', 'R'): -1, ('V', 'E'): -2,\n",
        "    ('T', 'N'): 0, ('P', 'P'): 7, ('V', 'I'): 3, ('V', 'S'): -2,\n",
        "    ('Z', 'P'): -1, ('V', 'M'): 1, ('T', 'F'): -2, ('V', 'Q'): -2,\n",
        "    ('K', 'K'): 5, ('P', 'D'): -1, ('I', 'H'): -3, ('I', 'D'): -3,\n",
        "    ('T', 'R'): -1, ('P', 'L'): -3, ('K', 'G'): -2, ('M', 'N'): -2,\n",
        "    ('P', 'H'): -2, ('F', 'Q'): -3, ('Z', 'G'): -2, ('X', 'L'): -1,\n",
        "    ('T', 'M'): -1, ('Z', 'C'): -3, ('X', 'H'): -1, ('D', 'R'): -2,\n",
        "    ('B', 'W'): -4, ('X', 'D'): -1, ('Z', 'K'): 1, ('F', 'A'): -2,\n",
        "    ('Z', 'W'): -3, ('F', 'E'): -3, ('D', 'N'): 1, ('B', 'K'): 0,\n",
        "    ('X', 'X'): -1, ('F', 'I'): 0, ('B', 'G'): -1, ('X', 'T'): 0,\n",
        "    ('F', 'M'): 0, ('B', 'C'): -3, ('Z', 'I'): -3, ('Z', 'V'): -2,\n",
        "    ('S', 'S'): 4, ('L', 'Q'): -2, ('W', 'E'): -3, ('Q', 'R'): 1,\n",
        "    ('N', 'N'): 6, ('W', 'M'): -1, ('Q', 'C'): -3, ('W', 'I'): -3,\n",
        "    ('S', 'C'): -1, ('L', 'A'): -1, ('S', 'G'): 0, ('L', 'E'): -3,\n",
        "    ('W', 'Q'): -2, ('H', 'G'): -2, ('S', 'K'): 0, ('Q', 'N'): 0,\n",
        "    ('N', 'R'): 0, ('H', 'C'): -3, ('Y', 'N'): -2, ('G', 'Q'): -2,\n",
        "    ('Y', 'F'): 3, ('C', 'A'): 0, ('V', 'L'): 1, ('G', 'E'): -2,\n",
        "    ('G', 'A'): 0, ('K', 'R'): 2, ('E', 'D'): 2, ('Y', 'R'): -2,\n",
        "    ('M', 'Q'): 0, ('T', 'I'): -1, ('C', 'D'): -3, ('V', 'F'): -1,\n",
        "    ('T', 'A'): 0, ('T', 'P'): -1, ('B', 'P'): -2, ('T', 'E'): -1,\n",
        "    ('V', 'N'): -3, ('P', 'G'): -2, ('M', 'A'): -1, ('K', 'H'): -1,\n",
        "    ('V', 'R'): -3, ('P', 'C'): -3, ('M', 'E'): -2, ('K', 'L'): -2,\n",
        "    ('V', 'V'): 4, ('M', 'I'): 1, ('T', 'Q'): -1, ('I', 'G'): -4,\n",
        "    ('P', 'K'): -1, ('M', 'M'): 5, ('K', 'D'): -1, ('I', 'C'): -1,\n",
        "    ('Z', 'D'): 1, ('F', 'R'): -3, ('X', 'K'): -1, ('Q', 'D'): 0,\n",
        "    ('X', 'G'): -1, ('Z', 'L'): -3, ('X', 'C'): -2, ('Z', 'H'): 0,\n",
        "    ('B', 'L'): -4, ('B', 'H'): 0, ('F', 'F'): 6, ('X', 'W'): -2,\n",
        "    ('B', 'D'): 4, ('D', 'A'): -2, ('S', 'L'): -2, ('X', 'S'): 0,\n",
        "    ('F', 'N'): -3, ('S', 'R'): -1, ('W', 'D'): -4, ('V', 'Y'): -1,\n",
        "    ('W', 'L'): -2, ('H', 'R'): 0, ('W', 'H'): -2, ('H', 'N'): 1,\n",
        "    ('W', 'T'): -2, ('T', 'T'): 5, ('S', 'F'): -2, ('W', 'P'): -4,\n",
        "    ('L', 'D'): -4, ('B', 'I'): -3, ('L', 'H'): -3, ('S', 'N'): 1,\n",
        "    ('B', 'T'): -1, ('L', 'L'): 4, ('Y', 'K'): -2, ('E', 'Q'): 2,\n",
        "    ('Y', 'G'): -3, ('Z', 'S'): 0, ('Y', 'C'): -2, ('G', 'D'): -1,\n",
        "    ('B', 'V'): -3, ('E', 'A'): -1, ('Y', 'W'): 2, ('E', 'E'): 5,\n",
        "    ('Y', 'S'): -2, ('C', 'N'): -3, ('V', 'C'): -1, ('T', 'H'): -2,\n",
        "    ('P', 'R'): -2, ('V', 'G'): -3, ('T', 'L'): -1, ('V', 'K'): -2,\n",
        "    ('K', 'Q'): 1, ('R', 'A'): -1, ('I', 'R'): -3, ('T', 'D'): -1,\n",
        "    ('P', 'F'): -4, ('I', 'N'): -3, ('K', 'I'): -3, ('M', 'D'): -3,\n",
        "    ('V', 'W'): -3, ('W', 'W'): 11, ('M', 'H'): -2, ('P', 'N'): -2,\n",
        "    ('K', 'A'): -1, ('M', 'L'): 2, ('K', 'E'): 1, ('Z', 'E'): 4,\n",
        "    ('X', 'N'): -1, ('Z', 'A'): -1, ('Z', 'M'): -1, ('X', 'F'): -1,\n",
        "    ('K', 'C'): -3, ('B', 'Q'): 0, ('X', 'B'): -1, ('B', 'M'): -3,\n",
        "    ('F', 'C'): -2, ('Z', 'Q'): 3, ('X', 'Z'): -1, ('F', 'G'): -3,\n",
        "    ('B', 'E'): 1, ('X', 'V'): -1, ('F', 'K'): -3, ('B', 'A'): -2,\n",
        "    ('X', 'R'): -1, ('D', 'D'): 6, ('W', 'G'): -2, ('Z', 'F'): -3,\n",
        "    ('S', 'Q'): 0, ('W', 'C'): -2, ('W', 'K'): -3, ('H', 'Q'): 0,\n",
        "    ('L', 'C'): -1, ('W', 'N'): -4, ('S', 'A'): 1, ('L', 'G'): -4,\n",
        "    ('W', 'S'): -3, ('S', 'E'): 0, ('H', 'E'): 0, ('S', 'I'): -2,\n",
        "    ('H', 'A'): -2, ('S', 'M'): -1, ('Y', 'L'): -1, ('Y', 'H'): 2,\n",
        "    ('Y', 'D'): -3, ('E', 'R'): 0, ('X', 'P'): -2, ('G', 'G'): 6,\n",
        "    ('G', 'C'): -3, ('E', 'N'): 0, ('Y', 'T'): -2, ('Y', 'P'): -3,\n",
        "    ('T', 'K'): -1, ('A', 'A'): 4, ('P', 'Q'): -1, ('T', 'C'): -1,\n",
        "    ('V', 'H'): -3, ('T', 'G'): -2, ('I', 'Q'): -3, ('Z', 'T'): -1,\n",
        "    ('C', 'R'): -3, ('V', 'P'): -2, ('P', 'E'): -1, ('M', 'C'): -1,\n",
        "    ('K', 'N'): 0, ('I', 'I'): 4, ('P', 'A'): -1, ('M', 'G'): -3,\n",
        "    ('T', 'S'): 1, ('I', 'E'): -3, ('P', 'M'): -2, ('M', 'K'): -1,\n",
        "    ('I', 'A'): -1, ('P', 'I'): -3, ('R', 'R'): 5, ('X', 'M'): -1,\n",
        "    ('L', 'I'): 2, ('X', 'I'): -1, ('Z', 'B'): 1, ('X', 'E'): -1,\n",
        "    ('Z', 'N'): 0, ('X', 'A'): 0, ('B', 'R'): -1, ('B', 'N'): 3,\n",
        "    ('F', 'D'): -3, ('X', 'Y'): -1, ('Z', 'R'): 0, ('F', 'H'): -1,\n",
        "    ('B', 'F'): -3, ('F', 'L'): 0, ('X', 'Q'): -1, ('B', 'B'): 4\n",
        "}\n",
        "\n",
        "Blosum62 = {}\n",
        "for i in blosum62:\n",
        "  Blosum62[i] = blosum62[i]\n",
        "  Blosum62[i[::-1]] = blosum62[i]\n",
        "if \".\" not in Sequence:\n",
        "  with open(\"sequence.txt\",\"w\") as w:\n",
        "    w.write(\">seq1\\n{o}\".format(o = Sequence))\n",
        "    w.close()\n",
        "  command = \"blastp -query {q} -db blastdb -out {o} -outfmt {f} -max_target_seqs {m} -evalue {e}\".format(q = \"sequence.txt\",d = \"blastdb\"\n",
        "  ,f = Blast_result_format,o = Blast_result_file_name , m = Max_target_Sequences , e = E_value_threshold)\n",
        "  exit_code, output = command_runner(command, shell=True, live_output=True)\n",
        "  files.download(Blast_result_file_name)\n",
        "  command = \"blastp -query {q} -db blastdb -out {o} -outfmt {f} -max_target_seqs {m} -evalue {e}\".format(q = \"sequence.txt\",d = \"blastdb\"\n",
        "  ,f = 6 ,o = \"results_dict.txt\" , m = Max_target_Sequences , e = E_value_threshold)\n",
        "  exit_code, output = command_runner(command, shell=True, live_output=True)\n",
        "\n",
        "  with open(\"results_dict.txt\") as w:\n",
        "    y = w.read()\n",
        "  idx = [i.split(\"\\t\")[1] for i in y.split(\"\\nseq\")]\n",
        "  for i in idx:\n",
        "    target_sequence = Dict[i]\n",
        "    aln = pairwise2.align.localds(Sequence,target_sequence, match_dict = Blosum62, open = -3, extend = -1)[0]\n",
        "    print(\"Subject_Id : \"+i+\"\\n\")\n",
        "    print(pairwise2.format_alignment(align1=aln[0], align2=aln[1], score=aln[2], begin=aln[3], end=aln[4], full_sequences=True))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "if \".\" in Sequence:\n",
        "  command = \"blastp -query {q} -db blastdb -out {o} -outfmt {f} -max_target_seqs {m} -evalue {e}\".format(q = Sequence,d = \"blastdb\"\n",
        "  ,f = Blast_result_format,o = Blast_result_file_name , m = Max_target_Sequences , e = E_value_threshold)\n",
        "  exit_code, output = command_runner(command, shell=True, live_output=True)\n",
        "  files.download(Blast_result_file_name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 558
        },
        "cellView": "form",
        "id": "Fd2CuI4MHUuM",
        "outputId": "23fb5d37-a50e-4a3e-ca31-6cb864853b0f"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: [blastp] Examining 5 or more matches is recommended\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_c1175267-dfcf-4d7e-b3c1-89c94d9dc31d\", \"result.txt\", 2645)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: [blastp] Examining 5 or more matches is recommended\n",
            "Subject_Id : seq90\n",
            "\n",
            "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------MAVRVAKMTEREKLLLKKYG--NRRL------YDTKRSAY----VTLSQ--VADIIKQGVD-V-EVVDAKTQEDVTAF-ILTQIVLEQARRKNALLPAEL--L----HLIIRYGE-DLLQEFFQKYLEQTIHGYIQFKKAMDEQFSKWIDMQLNYSDMAHKT-LSGLTRFPNIFSPPPGSP-GTKKDKG---------------------------------------------------------------------------------------------------------------\n",
            "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             |.|.....|.   ...|  .||.      |.....||    .||.|  .. ..|...| . ||      ..| .. .| ..|||  |    ..|..|  .    |..|.  | |  | .. |     .|....||....|....|..|.|...| |... |..||.  ||.|.....| | ...|                                                                                                                \n",
            "MAAESALQVVEKLQARLAANPDPKKLLKYLKKLSILPITVDILVETGVGKTVNSFRKHEQVGNFARDLVAQWKKLVPVERNSEAEDQDFEKNNSRKRPRDALQREEELEGNYQESWKPSGSRSYSPEHRQKKHKKLSEPERPHKVAHSHEKRDERKRCHKVSPPYSSDPESSDYGHVQSPPPSSPHQMYTDLSRSPEEDQEPIISHQKPGKVHSNTFQDRLGVSHLGEQGKGAVSHHKQHRSSHKEKHPADAREDEKISAVSREKSHKASSKEESRRLLSGDSAKEKLPSSVVKKDKDREGSSLKKKFSPALDVASDNHFKKPKHKDSEKAKSDKNKQSVDGVDSGRGTGDPLPKAKEKVPNHLKAQEGKVRTNADGKSAGPLHPKAEETDVDDEFERPTMSFESYLSYDQPRKKKKKVVKTSSTALGEKGLKKKDSKSTSKNLNSAQKLPKVNENKSEKLQPAGAEPTRPRKVPTDVLPALPDIPLPAIHANYRPLPSLELIPSFQPKRKAFSSPQEE---EEAGFTGRRMNSKMQVYSGSKCAYLPKMMTLHQQCIR-VLKNNIDSIFEV------GGV-PYSVL-EPVLE--R----CTPDQLYRIEECNHVLIE--ETD--Q-LW-K-----VHCHRDFKEERPEEYESWREMYLRLQD-AREQRLRLLTN--NIRSAHANKPKG-RQAKMAFVNSVAKPPRDVRRRQEKFGTGGAAVPEKVRIKPAPYTTGSSHVPASNSSSNFHSSPEELAYDGPSTSSAHLAPVASSSVSYDPRKPAVKKIAPMMAKTIKAFKNRFSRR\n",
            "  Score=141\n",
            "\n",
            "Subject_Id : seq683\n",
            "\n",
            "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------MAVRV---AKMTEREKLLLKKY-GNRRLYDTKRSAYVTLSQVADIIKQGVDVEVV-DAKTQE-DVTAFILTQIV-LE-QA-RR-KNA-LLPAELLHLIIRYGEDLLQE----FFQKYLEQTIHGY--I-QFKKAMDE-QFSKWIDMQLNYSDMAHKTLSGLTRFPNIFSPPPGSPGTKK--DKG----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "                                                                                                                                                                                                                                                                                                                                                                            ||.   |..|...  |.|.| ..|||.|   ||   |..| ||...|  |.|. |.|..| |.....| |.. .| .| .| ..| ......|.| .|..|..|||    ..|.|.|.. ||.  . |.||..|| . .|..|....| |.|  |...| |.   |.    .|..||  .|                                                                                                                                                                                                                                                                                                                                                                                                     \n",
            "MNDQTQFTERALTILTLAQKLASDHQHPQLQPIHILAAFIETPEDGSVPYLQNLIEKGRYDYDLFKKVVNRNLVRIPQQQPAPAEITPSYALGKVLQDAAKIQKQQKDSFIAQDHILFALFNDSSIQQIFKEAQVDIEAIKQQALELRGNTRIDSRGADTNTPLEYLSKYAIDMTEQARQGKLDPVIGREEEIRSTIRVLARRIKSNPCLIGEPGIGKTAIIEGVAQRIIDDDVPTILQGAKLFSLDLAALTAGAKYKGDFEERFKGVLKEIEESKTLIVLFIDEIHMLMGNGKDDAANILKPALSRGQLKVIGATTNNEYRSIVEKDGAFERRFQKIEVAEPSVRQTVAILRGLQPKYEIHHGVRILDSALVTAAQ--LAKRYLPYRRLPD---SA---LDLV-DISCAG--VAVARDSKPEELDSKERQL-QLIQVEIKALERDEDADSTTKDRLKL-ARQKEASLQEELEPLRQRYNEEK-HGHEELTQAKKKLDELE-NKALDAERRY-DTA--TAADL-RY---FA----IPDIKKQIEKLEDQVAEEERRAGANSMIQNVVDSDTISETAARLTGIPVKKLSESENEKLIHMERDLSSEVVGQMDAIKAVSNAVRLSRSGLANPRQPASFLFLGLSGSGKTELAKKVAGFLFNDEDMMIRVDCSELSEKYAVSKLLGTTAGYVGYDEGGFLTNQLQYKPYSVLLFDEVEKAHPDVLTVMLQMLDDGRITSGQGKTIDCSNCIVIMTSNLGAEFINSQQGSKIQESTKNLVMGAVRQHFRPEFLNRISSIVIFNKLSRKAIHKIVDIRLKEIEERFEQNDKHYKLNLTQEAKDFLAKYGYSDDMGARPLNRLIQNEILNKLALRILKNEIKDKETVNVVLKKGKSRDENVPEEAEECLEVLPNHEATIGADTLGDDDNEDSMEIDDDLD\n",
            "  Score=174\n",
            "\n",
            "Subject_Id : seq570\n",
            "\n",
            "---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------MAVRVAK-MT--EREKLL--LKKY-G-----NRRLYDTKR--SAYVTLSQVADIIK-QGVD--V----EVVD-AKTQEDVTAF-ILTQI-VLEQARRKNALLPAELLHLIIRYG--EDLLQEFFQKYLEQTIHG---YI---QFKKAMD---EQFSKWIDM--QLNYSD---MAHKTLSGLT-RF-PNIF---SPP---P--G-SP-------GTKKDKG----------------------------------------------------------------------------------------------------------\n",
            "                                                                                                                                                                                                                       ..||. ..  ||...|  .|.| |     |.|....|.  .|| .|...|   | |||.  |    ..|| .|..|..... ..|.. |.   |..|.  ......... ..  |........|. .|...|   |.   | .|  |   .|....|..  |..|..   .|.....|.. .| |..|   .||   |  | .|       |..|. |                                                                                                          \n",
            "MGSSHHHHHHHHASENLYFQSADITDKTAEQLENLNIQDDQKQAATGSESQSVENSSASLYVGDLEPSVSEAHLYDIFSPIGSVSSIRVCRDAITKTSLGYAYVNFNDHEAGRKAIEQLNYTPIKGRLCRIMWSQRDPSLRKKGSGNIFIKNLHPDIDNKALYDTFSVFGDILSSKIATDENGKSKGFGFVHFEEEGAAKEAIDALNGMLLNGQEIYVAPHLSRKERDSQLEETKLYVGRAQKKNERMHVLKKQYEAY-RLEKMA---KYQGVNLFVKNLDDSVDDEKLEEEFAPYGTITSAKVM---RTENG--KSKGFGFVC-FSTPEEATKAITEKN-QQIVAGKPLYVAIAQ-RK--DVRRSQLAQQIQARNQMRYQQATAAAAAAAAGMPGQFMPPMFYGVMPPRGVPFNGPNPQQMNPMGGMPKN-GMPPQFRNGPVYGVPPQGGFPRNANDNNQFYQQKQRQALGEQLYKKVSAKTSNEEAAGKITGMILDLPPQEVFPLLESDELFEQHYKEASAAYESFKKEQEQQTEQA\n",
            "  Score=155\n",
            "\n",
            "Subject_Id : seq566\n",
            "\n",
            "---------------------------------------------------------------------------------------------------------------------------MAVRVAK-M-TEREKLLLKK-YGN---RRLY---DTKRSA-YVTLSQV-ADII--KQGVDVEVVDAKTQEDVTAFILTQIVLEQARRKNALLPAELLH-LIIRYGEDLLQEFFQKYLEQTIHGYIQFKKAMDEQFSKWIDMQLNYSDMAH-KTL-SGLT--RFPNIFSP--PPGSPGTKKD-----KG-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "                                                                                                                              |... | ..|...|.|| .||   ..|.   |.|  | |.|.| | .||.  |...| |  ..|...  ..|....   |....|.|.   ..|. .... |    ||.   |...  |  .. .|..|.|..   .....|... . |.. |..|  .|...|..  |..|....||     ||                                                                                                                                                                                                                                         \n",
            "MGSSHHHHHHHHASENLYFQSADITDKTAEQLENLNIQDDQKQAATGSESQSVENSSASLYVGDLEPSVSEAHLYDIFSPIGSVSSIRVCRDAITKTSLGYAYVNFNDHEAGRKAIEQLNYTPIKGRLCRIMWSQRDPSLRKKGSGNIFIKNLHPDIDNK--ALYDTFS-VFGDILSSKIATD-E--NGKSKG--FGFVHFE---EEGAAKEAI---DALNGMLLN-G----QEI---YVAP--H--LS-RKERDSQLE---ETKAHYTNL-YVKNINSETTDEQFQELFAKFGPIVSASLEKDADGKLKGFGFVNYEKHEDAVKAVEALNDSELNGEKLYVGRAQKKNERMHVLKKQYEAYRLEKMAKYQGQLAQQIQARNQMRYQQATAAAAAAAAGMPGQFMPPMFYGVMPPRGVPFNGPNPQQMNPMGGMPKNGMPPQFRNGPVYGVPPQGGFPRNANDNNQFYQQKQRQALGEQLYKKVSAKTSNEEAAGKITGMILDLPPQEVFPLLESDELFEQHYKEASAAYESFKKEQEQQTEQA\n",
            "  Score=147\n",
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": [],
      "authorship_tag": "ABX9TyO4b3cmBSkgGn1aEqi1YvDA",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "9887b561461b47ccaf1c75a86496c259": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d42e26f75810496f99444f8ed31dbc82",
              "IPY_MODEL_dc4ec4f6ad3743ef9a443d239fa47e53",
              "IPY_MODEL_82e7ae2527e74436af3a409d58d03d10"
            ],
            "layout": "IPY_MODEL_97c833b9ed884edd8b9a89016d82f91c"
          }
        },
        "d42e26f75810496f99444f8ed31dbc82": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4b17280ab68a4dd7910a38bcc47fb6a2",
            "placeholder": "",
            "style": "IPY_MODEL_d7968132a13049a8a040b3b490ed3dc5",
            "value": "100%"
          }
        },
        "dc4ec4f6ad3743ef9a443d239fa47e53": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e5ef09c5c600401f92e7d0926758080a",
            "max": 702,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_483050b2c01d481aaeefb6155a9e528a",
            "value": 702
          }
        },
        "82e7ae2527e74436af3a409d58d03d10": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c5cf071e058644b8a215a83e8b87cc1c",
            "placeholder": "",
            "style": "IPY_MODEL_00623c962e814c1f9a0247ffe677e96b",
            "value": "702/702[02:00&lt;00:00,6.20it/s]"
          }
        },
        "97c833b9ed884edd8b9a89016d82f91c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4b17280ab68a4dd7910a38bcc47fb6a2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d7968132a13049a8a040b3b490ed3dc5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e5ef09c5c600401f92e7d0926758080a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "483050b2c01d481aaeefb6155a9e528a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c5cf071e058644b8a215a83e8b87cc1c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "00623c962e814c1f9a0247ffe677e96b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
